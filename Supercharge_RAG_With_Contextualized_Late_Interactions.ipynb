{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8vjtfJxGN2BJEvWr69FFC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5f6f9d04fcb34f268ec31a070aaf6bb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a6634c0145e446ba07bfce9903adfd4",
              "IPY_MODEL_60abc1bb2f614ccca29d31794e2aeb46",
              "IPY_MODEL_4ad671b44be0438390a766dd35484c2d"
            ],
            "layout": "IPY_MODEL_93b9b66818734e4faf2b3222d91cfb7e"
          }
        },
        "0a6634c0145e446ba07bfce9903adfd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_972dc0692ee44846bb1f3f132400ee92",
            "placeholder": "​",
            "style": "IPY_MODEL_92fa8077a55b4e3a9ece61cd251cde56",
            "value": "artifact.metadata: 100%"
          }
        },
        "60abc1bb2f614ccca29d31794e2aeb46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1d05a90aaf44ae2bae0b3dbc2119d7c",
            "max": 1633,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4584ee9bd0724544b27f7de4a3943d53",
            "value": 1633
          }
        },
        "4ad671b44be0438390a766dd35484c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31c14c1de1cb4e269f468a6416f438b9",
            "placeholder": "​",
            "style": "IPY_MODEL_b64e52a6bc0043f5aaaea4ad625e028e",
            "value": " 1.63k/1.63k [00:00&lt;00:00, 76.5kB/s]"
          }
        },
        "93b9b66818734e4faf2b3222d91cfb7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "972dc0692ee44846bb1f3f132400ee92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92fa8077a55b4e3a9ece61cd251cde56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1d05a90aaf44ae2bae0b3dbc2119d7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4584ee9bd0724544b27f7de4a3943d53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31c14c1de1cb4e269f468a6416f438b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b64e52a6bc0043f5aaaea4ad625e028e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "019ed65d4c5c4d2f9d8200cba1db6c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b148db5df0e404f821a2d5020c8df11",
              "IPY_MODEL_854ed825f7f143d595fb2f875af18482",
              "IPY_MODEL_0c0b08c33c1d4aa7b5963889da3c6182"
            ],
            "layout": "IPY_MODEL_22e3e0e33fe542d4a2eb767ae500892a"
          }
        },
        "3b148db5df0e404f821a2d5020c8df11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6841d2d78f464cd1b0e31d40986e9c17",
            "placeholder": "​",
            "style": "IPY_MODEL_fe6cf2d61f31447bba5189a339e47903",
            "value": "config.json: 100%"
          }
        },
        "854ed825f7f143d595fb2f875af18482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0590d0ca08484d3e8f61f01c5e7c849e",
            "max": 743,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64199877582649529680519152c17d06",
            "value": 743
          }
        },
        "0c0b08c33c1d4aa7b5963889da3c6182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_859b3c79e4b14696ada7f80794270dfa",
            "placeholder": "​",
            "style": "IPY_MODEL_750ed0beb396436bba2fa2bf518400cf",
            "value": " 743/743 [00:00&lt;00:00, 34.4kB/s]"
          }
        },
        "22e3e0e33fe542d4a2eb767ae500892a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6841d2d78f464cd1b0e31d40986e9c17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe6cf2d61f31447bba5189a339e47903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0590d0ca08484d3e8f61f01c5e7c849e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64199877582649529680519152c17d06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "859b3c79e4b14696ada7f80794270dfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "750ed0beb396436bba2fa2bf518400cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24bb7d3e4ad24c4fa8935cc280439c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73b49e3b7c6545318b90ebff94eb1196",
              "IPY_MODEL_b74028c063584b6291d20e043e247053",
              "IPY_MODEL_fc3d23b79b904ef48a637eedd15bc526"
            ],
            "layout": "IPY_MODEL_297d33ae48f2477a8e4ba06e6ccd0e89"
          }
        },
        "73b49e3b7c6545318b90ebff94eb1196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6966dfa918bd41eeac255720906893be",
            "placeholder": "​",
            "style": "IPY_MODEL_dd5bbbdbd5da4a1ebc7908345c2be159",
            "value": "model.safetensors: 100%"
          }
        },
        "b74028c063584b6291d20e043e247053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90fcca5e6805490788d4c681ded61993",
            "max": 438349816,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_677aef653cbc4cd8833065391362aafb",
            "value": 438349816
          }
        },
        "fc3d23b79b904ef48a637eedd15bc526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97847a7cf06441699aea11b5684a6821",
            "placeholder": "​",
            "style": "IPY_MODEL_65fecea47aab4d27b6c9fa5b1feff2e6",
            "value": " 438M/438M [00:07&lt;00:00, 103MB/s]"
          }
        },
        "297d33ae48f2477a8e4ba06e6ccd0e89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6966dfa918bd41eeac255720906893be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd5bbbdbd5da4a1ebc7908345c2be159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90fcca5e6805490788d4c681ded61993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "677aef653cbc4cd8833065391362aafb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97847a7cf06441699aea11b5684a6821": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65fecea47aab4d27b6c9fa5b1feff2e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a6fe5b34ebc44d5ab9020a650d66c08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1acd52edd1ee4ae0b18ec21c15541227",
              "IPY_MODEL_1758cc64c1d0485ea21869688e82a500",
              "IPY_MODEL_56f5ca57140e4f678595102351950e73"
            ],
            "layout": "IPY_MODEL_e6c157a04d13485dbfd0ab820384d3ad"
          }
        },
        "1acd52edd1ee4ae0b18ec21c15541227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1827ed49676e43018d983f4a718129df",
            "placeholder": "​",
            "style": "IPY_MODEL_1d44298a25e645a48331f90afedf6f7a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1758cc64c1d0485ea21869688e82a500": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_723be54aa3c04e558d34a4423430a347",
            "max": 405,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7453fee093b34c3badc387b6cbabbcdc",
            "value": 405
          }
        },
        "56f5ca57140e4f678595102351950e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec9bd6d48bca4b46aca44926cb5c6237",
            "placeholder": "​",
            "style": "IPY_MODEL_4a1404dadcfd4370988dce8b1f5181ad",
            "value": " 405/405 [00:00&lt;00:00, 25.8kB/s]"
          }
        },
        "e6c157a04d13485dbfd0ab820384d3ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1827ed49676e43018d983f4a718129df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d44298a25e645a48331f90afedf6f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "723be54aa3c04e558d34a4423430a347": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7453fee093b34c3badc387b6cbabbcdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec9bd6d48bca4b46aca44926cb5c6237": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a1404dadcfd4370988dce8b1f5181ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e5ce35143e1459783b633558b86ee0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74e0b1abc9a04438842c13d7b53e7adb",
              "IPY_MODEL_8ef6da09ff014c21a75bb3b665603d8b",
              "IPY_MODEL_827276dec42d4114863e22f780a7ec2a"
            ],
            "layout": "IPY_MODEL_b5f4c7dfa8b144818a560ed498c80a0e"
          }
        },
        "74e0b1abc9a04438842c13d7b53e7adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d74ec5f8190e44479c19579fca269194",
            "placeholder": "​",
            "style": "IPY_MODEL_afb8dce0b66c4ac9bae30af6e38dfc2a",
            "value": "vocab.txt: 100%"
          }
        },
        "8ef6da09ff014c21a75bb3b665603d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5201baa14e874cc8bdb09f7efb35fe26",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58d9f21552d847199fff3f3a3cbcb65e",
            "value": 231508
          }
        },
        "827276dec42d4114863e22f780a7ec2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c6a82a2b3c949fc9c87342e3d909134",
            "placeholder": "​",
            "style": "IPY_MODEL_8f5963127ab8473998b51127b11d2224",
            "value": " 232k/232k [00:00&lt;00:00, 3.96MB/s]"
          }
        },
        "b5f4c7dfa8b144818a560ed498c80a0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d74ec5f8190e44479c19579fca269194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afb8dce0b66c4ac9bae30af6e38dfc2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5201baa14e874cc8bdb09f7efb35fe26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58d9f21552d847199fff3f3a3cbcb65e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c6a82a2b3c949fc9c87342e3d909134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f5963127ab8473998b51127b11d2224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f48b3bae4ddc4454be9bee98e9384c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_348757a7be634333855de66b879959ea",
              "IPY_MODEL_5f20d410f021400a8e8e8dc71246f4c0",
              "IPY_MODEL_c5f9629b7b7641c5b1d48def3852581e"
            ],
            "layout": "IPY_MODEL_0974088c8d114d2b93d8d3aeb86d9b3f"
          }
        },
        "348757a7be634333855de66b879959ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b0eae06417b4c5fb53615c9c8cc0299",
            "placeholder": "​",
            "style": "IPY_MODEL_e6ac854eb0d646c98a1088003303c682",
            "value": "tokenizer.json: 100%"
          }
        },
        "5f20d410f021400a8e8e8dc71246f4c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b73eca0fb3014138a2717b7770b6a371",
            "max": 466081,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_673ff1dbb519492a91bef1b2ff5ae0f9",
            "value": 466081
          }
        },
        "c5f9629b7b7641c5b1d48def3852581e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa793faaf21849ab842cd670ae8d618d",
            "placeholder": "​",
            "style": "IPY_MODEL_10e91ddb3acb48289d34a48e8c167b3b",
            "value": " 466k/466k [00:00&lt;00:00, 12.6MB/s]"
          }
        },
        "0974088c8d114d2b93d8d3aeb86d9b3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b0eae06417b4c5fb53615c9c8cc0299": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6ac854eb0d646c98a1088003303c682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b73eca0fb3014138a2717b7770b6a371": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "673ff1dbb519492a91bef1b2ff5ae0f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa793faaf21849ab842cd670ae8d618d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10e91ddb3acb48289d34a48e8c167b3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b5f76d849b5443e9d2d12e73e98c142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c59db7bb402240498d9bd06426d76ec7",
              "IPY_MODEL_90f929e022424772920d0ea3a23eebba",
              "IPY_MODEL_4b7267e0994349969498236737ea5d06"
            ],
            "layout": "IPY_MODEL_0ac1d9a0627b4038b67e0f239489b0b8"
          }
        },
        "c59db7bb402240498d9bd06426d76ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_959a5c46e66e47828fb2ee8127926959",
            "placeholder": "​",
            "style": "IPY_MODEL_f60fa66de69249b3b139f3ecc535bf78",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "90f929e022424772920d0ea3a23eebba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5271ee2578a14c4b804d1869d96fbd6a",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_736f630bc0f54fb0a12204f66d8ac31c",
            "value": 112
          }
        },
        "4b7267e0994349969498236737ea5d06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38544423f3884bcbb5d0444ebfa28a96",
            "placeholder": "​",
            "style": "IPY_MODEL_69c52b232e384775a2cb73db36b9c767",
            "value": " 112/112 [00:00&lt;00:00, 4.97kB/s]"
          }
        },
        "0ac1d9a0627b4038b67e0f239489b0b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "959a5c46e66e47828fb2ee8127926959": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f60fa66de69249b3b139f3ecc535bf78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5271ee2578a14c4b804d1869d96fbd6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "736f630bc0f54fb0a12204f66d8ac31c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38544423f3884bcbb5d0444ebfa28a96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69c52b232e384775a2cb73db36b9c767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "363892c16afc4ff69c0b2386aed20480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_685da684f5d64f40bcfbe1a5c2e9937e",
              "IPY_MODEL_b47447eec06c4a20ba4a2b7aa6fc7076",
              "IPY_MODEL_68450ab5f1e64bf096fcbba1b579d962"
            ],
            "layout": "IPY_MODEL_eab7c71c4aef4e53a96796ad1609b96c"
          }
        },
        "685da684f5d64f40bcfbe1a5c2e9937e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c94931c5e9e47c38a15381527f99fdb",
            "placeholder": "​",
            "style": "IPY_MODEL_4cdb20077f4d4055b088ec794b597ff4",
            "value": "artifact.metadata: 100%"
          }
        },
        "b47447eec06c4a20ba4a2b7aa6fc7076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e699957e2aa4ea4bb610f5d302e5f52",
            "max": 1633,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae5ab13ae07c4bac9cfaa56fd2b06545",
            "value": 1633
          }
        },
        "68450ab5f1e64bf096fcbba1b579d962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a70e6ab0513943739c6d636d2857bd17",
            "placeholder": "​",
            "style": "IPY_MODEL_454939afd6914f658170e0664db35975",
            "value": " 1.63k/1.63k [00:00&lt;00:00, 43.3kB/s]"
          }
        },
        "eab7c71c4aef4e53a96796ad1609b96c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c94931c5e9e47c38a15381527f99fdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cdb20077f4d4055b088ec794b597ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e699957e2aa4ea4bb610f5d302e5f52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae5ab13ae07c4bac9cfaa56fd2b06545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a70e6ab0513943739c6d636d2857bd17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "454939afd6914f658170e0664db35975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56042d89e5034c3592793ed63e703c5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db1fd8d168d846c19a1c8a88d6babdff",
              "IPY_MODEL_e00363f29ff3485e97434d34385c7b03",
              "IPY_MODEL_0f7f8683d03b48df9175d2e8ec895503"
            ],
            "layout": "IPY_MODEL_f94ce0f19191443ead21a69607068b96"
          }
        },
        "db1fd8d168d846c19a1c8a88d6babdff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac344d33917c419ca4873ae9518bbf93",
            "placeholder": "​",
            "style": "IPY_MODEL_e81eac2dbc2b4b40bf232d957e590b92",
            "value": "config.json: 100%"
          }
        },
        "e00363f29ff3485e97434d34385c7b03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9dbbd290e89493c81525ce31ea189d5",
            "max": 743,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d78968a8cb694fb4947c8e8e7ead44a3",
            "value": 743
          }
        },
        "0f7f8683d03b48df9175d2e8ec895503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_174d3b5e6d50403a9adf760ddeb9c64c",
            "placeholder": "​",
            "style": "IPY_MODEL_d4e4d35682fe4166812b71f95ae6aa5b",
            "value": " 743/743 [00:00&lt;00:00, 16.4kB/s]"
          }
        },
        "f94ce0f19191443ead21a69607068b96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac344d33917c419ca4873ae9518bbf93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e81eac2dbc2b4b40bf232d957e590b92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9dbbd290e89493c81525ce31ea189d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d78968a8cb694fb4947c8e8e7ead44a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "174d3b5e6d50403a9adf760ddeb9c64c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4e4d35682fe4166812b71f95ae6aa5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9702bf17af684e948886e4416227bf04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2fad5676786497f8cb2b3923a80479f",
              "IPY_MODEL_c366849fd1ad4e0980a1603086b5f660",
              "IPY_MODEL_3d558c422e574cecb25911c4d8c2def1"
            ],
            "layout": "IPY_MODEL_a612195ccefa44f58bd8704be4944f8d"
          }
        },
        "d2fad5676786497f8cb2b3923a80479f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5b387899b6245c9a4b90ce7b1ba0653",
            "placeholder": "​",
            "style": "IPY_MODEL_ac907a44f1314996ba8c5a46c173f489",
            "value": "model.safetensors: 100%"
          }
        },
        "c366849fd1ad4e0980a1603086b5f660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55b30692030848c0b12e1f3e1abe12ff",
            "max": 438349816,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01992549e3e24725bb4728556911ba07",
            "value": 438349816
          }
        },
        "3d558c422e574cecb25911c4d8c2def1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c81190bb7e5a4e8a8829f3728031508a",
            "placeholder": "​",
            "style": "IPY_MODEL_a522af96819742be9f72a68fe1ff0018",
            "value": " 438M/438M [00:07&lt;00:00, 57.1MB/s]"
          }
        },
        "a612195ccefa44f58bd8704be4944f8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5b387899b6245c9a4b90ce7b1ba0653": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac907a44f1314996ba8c5a46c173f489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55b30692030848c0b12e1f3e1abe12ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01992549e3e24725bb4728556911ba07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c81190bb7e5a4e8a8829f3728031508a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a522af96819742be9f72a68fe1ff0018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa0be30c32d24052a8c1e18a46afb892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_780678f132e2467d93518b1976278525",
              "IPY_MODEL_a4d2036bd4d6471b8f1a53a09f5c73a5",
              "IPY_MODEL_046f3e1bb58948378e4662d74ac2a157"
            ],
            "layout": "IPY_MODEL_757d9bf337434e0da8ceb279e992c63b"
          }
        },
        "780678f132e2467d93518b1976278525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a26530b198e4fcaabfd27a41fe91297",
            "placeholder": "​",
            "style": "IPY_MODEL_04637f70e3cb46239919c7a548e77fcf",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a4d2036bd4d6471b8f1a53a09f5c73a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80ce0fa84a784559acf994a5e0e12711",
            "max": 405,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fec920793dd84e609dce910ca317e96e",
            "value": 405
          }
        },
        "046f3e1bb58948378e4662d74ac2a157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_731466317d64474ba4b5564e6dfdd5fd",
            "placeholder": "​",
            "style": "IPY_MODEL_fc63be73435c44f9ab0808504774400e",
            "value": " 405/405 [00:00&lt;00:00, 33.1kB/s]"
          }
        },
        "757d9bf337434e0da8ceb279e992c63b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a26530b198e4fcaabfd27a41fe91297": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04637f70e3cb46239919c7a548e77fcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80ce0fa84a784559acf994a5e0e12711": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fec920793dd84e609dce910ca317e96e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "731466317d64474ba4b5564e6dfdd5fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc63be73435c44f9ab0808504774400e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55cc5ea7cf104730b33d32f69c1b8d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54c41b3cc1c64c85afff10a29e52f81e",
              "IPY_MODEL_f529abd39a884c15bac0542fd5aec1e4",
              "IPY_MODEL_aee19a7a11824487b80668ed9bf55b22"
            ],
            "layout": "IPY_MODEL_b870baedefc34221a1fe37a985a1e42d"
          }
        },
        "54c41b3cc1c64c85afff10a29e52f81e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab3be5da2be049829747a4f21ffb1808",
            "placeholder": "​",
            "style": "IPY_MODEL_a552cfdc183045d1a003f66328ec1348",
            "value": "vocab.txt: 100%"
          }
        },
        "f529abd39a884c15bac0542fd5aec1e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_621103b3cc7f4ce5986d2819d224ee4e",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11e5e8e94e784b4b8fe43fed8bd60a28",
            "value": 231508
          }
        },
        "aee19a7a11824487b80668ed9bf55b22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e37dd9e5b264374be5f1127f3972d1b",
            "placeholder": "​",
            "style": "IPY_MODEL_010153f29dbc47da99a87e36db559802",
            "value": " 232k/232k [00:00&lt;00:00, 579kB/s]"
          }
        },
        "b870baedefc34221a1fe37a985a1e42d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab3be5da2be049829747a4f21ffb1808": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a552cfdc183045d1a003f66328ec1348": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "621103b3cc7f4ce5986d2819d224ee4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11e5e8e94e784b4b8fe43fed8bd60a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e37dd9e5b264374be5f1127f3972d1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "010153f29dbc47da99a87e36db559802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd5640c7a9fe43009eb1abd29fc1335c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2befdf2448e14b3d957e086c3b333216",
              "IPY_MODEL_6823425fa66a4170ac037942cfdfd66d",
              "IPY_MODEL_0ec10b754ba7405bbdef7d5580f17c79"
            ],
            "layout": "IPY_MODEL_8c7c9073e6b848e1ad8a5095e1879ee3"
          }
        },
        "2befdf2448e14b3d957e086c3b333216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5eefbdd09014d34848dbe690d98ecc0",
            "placeholder": "​",
            "style": "IPY_MODEL_de95baef449d42d79ab4172dfa60efe1",
            "value": "tokenizer.json: 100%"
          }
        },
        "6823425fa66a4170ac037942cfdfd66d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18c91d04bcf7484f914403dffff03d21",
            "max": 466081,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6188f31fef9440138f8519637998793c",
            "value": 466081
          }
        },
        "0ec10b754ba7405bbdef7d5580f17c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5ba7160bee14750aaaea60b0b30d643",
            "placeholder": "​",
            "style": "IPY_MODEL_a44ef52b015440e184b09232373ed9c1",
            "value": " 466k/466k [00:00&lt;00:00, 1.17MB/s]"
          }
        },
        "8c7c9073e6b848e1ad8a5095e1879ee3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5eefbdd09014d34848dbe690d98ecc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de95baef449d42d79ab4172dfa60efe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18c91d04bcf7484f914403dffff03d21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6188f31fef9440138f8519637998793c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5ba7160bee14750aaaea60b0b30d643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a44ef52b015440e184b09232373ed9c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "120d40218b614594ae29f7c50dfe028e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6512786a54da43eeaac0fc79c64862b0",
              "IPY_MODEL_f94e2a16be1d4d2d9f47defbfb9876f4",
              "IPY_MODEL_9c276bd8eb1f4934a6848de6f9356214"
            ],
            "layout": "IPY_MODEL_7a81cbf226fe4934aa0a2193de741834"
          }
        },
        "6512786a54da43eeaac0fc79c64862b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98e023150de0463cb74594b04c8562f5",
            "placeholder": "​",
            "style": "IPY_MODEL_dc61936f6ef3452fa5523e56807a2a27",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "f94e2a16be1d4d2d9f47defbfb9876f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60b831fddbb744a3b22a8b5b2ac9e13e",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_421e2d05c26a4e7389534d0c852a0e71",
            "value": 112
          }
        },
        "9c276bd8eb1f4934a6848de6f9356214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0154058a0bb9430386bf26e22a3fb2d7",
            "placeholder": "​",
            "style": "IPY_MODEL_f139c959577544988eb9579538245443",
            "value": " 112/112 [00:00&lt;00:00, 9.04kB/s]"
          }
        },
        "7a81cbf226fe4934aa0a2193de741834": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98e023150de0463cb74594b04c8562f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc61936f6ef3452fa5523e56807a2a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60b831fddbb744a3b22a8b5b2ac9e13e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "421e2d05c26a4e7389534d0c852a0e71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0154058a0bb9430386bf26e22a3fb2d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f139c959577544988eb9579538245443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plaban1981/Langchain_usecases/blob/main/Supercharge_RAG_With_Contextualized_Late_Interactions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install required dependencies"
      ],
      "metadata": {
        "id": "gY5q_MNAO9Qr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09ZSyTNkMd3X",
        "outputId": "6377ecb5-f568-489b-df66-fc3f7f9bb6d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.9/103.9 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for html2text (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.3/299.3 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.3/288.3 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.0/116.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for colbert-ai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "ERROR: unknown command \"intall\" - maybe you meant \"install\"\n",
            "Collecting llama-index-embeddings-huggingface\n",
            "  Downloading llama_index_embeddings_huggingface-0.2.0-py3-none-any.whl (7.1 kB)\n",
            "Requirement already satisfied: huggingface-hub[inference]>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-huggingface) (0.22.2)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-huggingface) (0.10.33)\n",
            "Collecting sentence-transformers<3.0.0,>=2.6.1 (from llama-index-embeddings-huggingface)\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.11.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.9.5)\n",
            "Collecting minijinja>=1.0 (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n",
            "  Downloading minijinja-1.0.16-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (804 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m804.6/804.6 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.0.29)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.6.4)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.8)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.1.19)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.23.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (9.4.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.6.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.14.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (4.40.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (2.2.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (1.11.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.0.3)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.7.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.0.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (12.4.127)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (0.4.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (3.4.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
            "Installing collected packages: minijinja, sentence-transformers, llama-index-embeddings-huggingface\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 2.3.0\n",
            "    Uninstalling sentence-transformers-2.3.0:\n",
            "      Successfully uninstalled sentence-transformers-2.3.0\n",
            "Successfully installed llama-index-embeddings-huggingface-0.2.0 minijinja-1.0.16 sentence-transformers-2.7.0\n",
            "Collecting llama-index-vector-stores-faiss\n",
            "  Downloading llama_index_vector_stores_faiss-0.1.2-py3-none-any.whl (3.6 kB)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-vector-stores-faiss) (0.10.33)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (0.6.4)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (0.1.19)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.23.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (4.11.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.14.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (4.0.3)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2.7.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (3.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.2.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.16.0)\n",
            "Installing collected packages: llama-index-vector-stores-faiss\n",
            "Successfully installed llama-index-vector-stores-faiss-0.1.2\n",
            "ERROR: unknown command \"intall\" - maybe you meant \"install\"\n"
          ]
        }
      ],
      "source": [
        "!pip install -q llama-hub\n",
        "!pip install -q arxiv\n",
        "!pip install -q semanticscholar\n",
        "!pip install -q sentence-transformers==2.3.0\n",
        "!pip install -q ragatouille\n",
        "!pip install -q llama-index\n",
        "!pip install -q llama-index-readers-file\n",
        "!pip intall -q llama-index-llms-openai\n",
        "!pip install -q llama-index-core\n",
        "!pip install llama-index-embeddings-huggingface\n",
        "!pip install llama-index-vector-stores-faiss\n",
        "!pip install -q langchain\n",
        "!pip install -q langchain-core\n",
        "!pip intall -q langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "linkify-it-py==2.0.3\n",
        "llama-hub==0.0.79.post1\n",
        "llama-index==0.10.30\n",
        "llama-index-agent-openai==0.2.2\n",
        "llama-index-cli==0.1.12\n",
        "llama-index-core==0.10.30\n",
        "llama-index-embeddings-huggingface==0.2.0\n",
        "llama-index-embeddings-openai==0.1.8\n",
        "llama-index-indices-managed-llama-cloud==0.1.5\n",
        "llama-index-legacy==0.9.48\n",
        "llama-index-llms-openai==0.1.16\n",
        "llama-index-multi-modal-llms-openai==0.1.5\n",
        "llama-index-program-openai==0.1.5\n",
        "llama-index-question-gen-openai==0.1.3\n",
        "llama-index-readers-file==0.1.19\n",
        "llama-index-readers-llama-parse==0.1.4\n",
        "llama-index-vector-stores-faiss==0.1.2\n",
        "llama-parse==0.4.1\n",
        "RAGatouille==0.0.8.post2\n",
        "```"
      ],
      "metadata": {
        "id": "UbGdw-gpROAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Dataset"
      ],
      "metadata": {
        "id": "JBAHSghJRgsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://arxiv.org/pdf/2306.02707.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCHa_w3vRFMT",
        "outputId": "5d19f46f-9c78-4bf3-bad3-7b4ff7e08a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-28 14:41:07--  https://arxiv.org/pdf/2306.02707.pdf\n",
            "Resolving arxiv.org (arxiv.org)... 151.101.67.42, 151.101.131.42, 151.101.3.42, ...\n",
            "Connecting to arxiv.org (arxiv.org)|151.101.67.42|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://arxiv.org/pdf/2306.02707 [following]\n",
            "--2024-04-28 14:41:08--  http://arxiv.org/pdf/2306.02707\n",
            "Connecting to arxiv.org (arxiv.org)|151.101.67.42|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1458242 (1.4M) [application/pdf]\n",
            "Saving to: ‘2306.02707.pdf’\n",
            "\n",
            "2306.02707.pdf      100%[===================>]   1.39M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-04-28 14:41:08 (20.3 MB/s) - ‘2306.02707.pdf’ saved [1458242/1458242]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.readers.file import PDFReader\n",
        "loader = PDFReader()\n",
        "documents = loader.load_data(\"2306.02707.pdf\")"
      ],
      "metadata": {
        "id": "nY_-3EktTZOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(documents))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5bSyN3rUBrH",
        "outputId": "b40989ca-1db6-4387-8a4a-1e69ed306e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_documents = [ document.text for document in documents ]"
      ],
      "metadata": {
        "id": "xSReG5k_UDlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Opensource Embedding Model"
      ],
      "metadata": {
        "id": "0Wky8R4eUPhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.embed_model = HuggingFaceEmbedding(\n",
        "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
        ")"
      ],
      "metadata": {
        "id": "DU8IeRq_UTE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import (\n",
        "    SimpleDirectoryReader,\n",
        "    load_index_from_storage,\n",
        "    VectorStoreIndex,\n",
        "    StorageContext,\n",
        ")\n",
        "from llama_index.vector_stores.faiss import FaissVectorStore"
      ],
      "metadata": {
        "id": "KQATo4Q9a7Yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndex.from_documents(documents)"
      ],
      "metadata": {
        "id": "QlsaKpp9bH6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query Index"
      ],
      "metadata": {
        "id": "FA-EEuLJbQ5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriver = index.as_retriever(similarity_top_k=3)"
      ],
      "metadata": {
        "id": "qPmDR8P1bYwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_docs = retriver.retrieve(\"What is instruction tuning?\")"
      ],
      "metadata": {
        "id": "P3ZJln2mdap5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_docs1 = retriver.retrieve(\"What is orca?\")"
      ],
      "metadata": {
        "id": "Z_WNWK0jkbxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.response.notebook_utils import display_source_node\n",
        "for node in similar_docs1:\n",
        "  display_source_node(node)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "uTSyw9Q0ki34",
        "outputId": "eb471431-0587-44a5-943b-60825f183ead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** 144c4c2e-681f-444d-bd3f-98b745b28c06<br>**Similarity:** 0.6652078795266653<br>**Text:** For Vicuna and Orca the format of the prompt is as follows:\n### System:\n### Human:\nQ: Which blood...<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** 98e45e23-9d19-4e6a-bc0e-adcd2561e554<br>**Similarity:** 0.6508155769295554<br>**Text:** Task / System Message Empty Follow Well Detailed Answer\nAQuA-RAT 27.9 21.3 25.2\nLogiQA 35.2 36.4 ...<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** cbd45178-6472-4bbe-b435-78ebf64e2ad3<br>**Similarity:** 0.6503899050959893<br>**Text:** 0102030405060708090AQuA-RAT (GRE Math, GMAT Math)\nLogiQA (English, Civil Services)\nLSAT-AR\nLSAT-L...<br>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.response.notebook_utils import display_source_node\n",
        "for node in similar_docs:\n",
        "  display_source_node(node)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "SVQpuxeqdnXg",
        "outputId": "f7028dd9-3671-4e58-823d-6687f331d2b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** 61299ed3-a6eb-4f9f-917a-9f731f154305<br>**Similarity:** 0.7422756912118058<br>**Text:** Model Tuning Method Data Size Teacher\nAlpaca Simple Instructions / Self-instruct 52K text-da-vinc...<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** 074197f9-75d9-48e4-91a6-59665ae927d8<br>**Similarity:** 0.7226097983044915<br>**Text:** Contents\n1 Introduction 4\n1.1 Challenges with Existing Methods . . . . . . . . . . . . . . . . . ...<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** 6469e949-d4d8-40f4-be8f-836abf0e44c5<br>**Similarity:** 0.703846265300339<br>**Text:** content generation and information-seeking queries over other types of tasks. Therefore,\nmodels t...<br>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir open_source\n",
        "# save index to disk\n",
        "index.storage_context.persist(\"/content/open_source\")"
      ],
      "metadata": {
        "id": "bxbnyMgukwk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,node in enumerate(similar_docs):\n",
        "  print(f\"------------------ {i} ----------------------------------------------------\")\n",
        "  print(node.text)\n",
        "  print(\"----------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg1wngRddzu4",
        "outputId": "d32807b3-31f9-4e80-eadb-7fe53cad391f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------ 0 ----------------------------------------------------\n",
            "Model Tuning Method Data Size Teacher\n",
            "Alpaca Simple Instructions / Self-instruct 52K text-da-vinci-003\n",
            "Vicuna User Instructions / Natural 70K ChatGPT\n",
            "Dolly User Instructions / Natural 15K Human\n",
            "WizardLM Complex Instructions / Evol-instruct 250K ChatGPT\n",
            "Orca Complex Instructions / Explanations 5M ChatGPT (5M)\n",
            "∩GPT-4 (1M)\n",
            "Table 1: Overview of popular models instruction tuned with OpenAI large foundation models\n",
            "(LFMs). Orca leverages complex instructions and explanations for progressive learning.\n",
            "User Instruction: Use the given data to calculate the median. \n",
            "Input:[7, 3, 8, 2, 10]\n",
            "User Instruction: Answer this question.\n",
            "Input:Which small lake lies between Windermere and Grasmere?User Instruction: In this task, you will be presented with a question having \n",
            "multiple possible answers in Italian language. And you should choose a most \n",
            "suitable option out of \"A\", \"B\", \"C\", \"D\", and \"E\" based on your commonsense \n",
            "knowledge. \n",
            "Input:Solve this question: Dove non riusciresti a vedere la luce? \n",
            "Options: A scrivaniaB frigoriferoC sole D universoE atticoOutput: First, we need to arrange the data in ascending order: [2, 3, 7, 8, 10]. \n",
            "Since there are 5 numbers, the median is the middle number, which is 7.\n",
            "Output: B frigorifero\n",
            "Output: Rydal Water lies between Windermere and Grasmere.\n",
            "Figure 4: Instruction-tuning with GPT-49. Given user instructions for a task and an input,\n",
            "the system generates a response. Existing works like Alpaca [ 7], Vicuna [ 9] and variants\n",
            "follow a similar template to train small models with ⟨{user instruction, input}, output ⟩.\n",
            "2 Preliminaries\n",
            "2.1 Instruction Tuning\n",
            "Instruction tuning [ 22] is a technique that allows pre-trained language models to learn\n",
            "from input (natural language descriptions of the task) and response pairs, for example,\n",
            "{\"instruction\": \"Arrange the words in the given sentence to form a grammatically\n",
            "correct sentence.\", \"input\": \"the quickly brown fox jumped\", \"output\": \"the brown\n",
            "fox jumped quickly\"} . Instruction tuning has been applied to both language-only and\n",
            "multimodal tasks. For language-only tasks, instruction tuning has been shown to improve\n",
            "the zero-shot and few-shot performance of models such as FLAN [ 22] and InstructGPT [ 5]\n",
            "on various benchmarks. For multimodal tasks, instruction tuning has been used to generate\n",
            "synthetic instruction-following data for language-image tasks, such as image captioning [ 23]\n",
            "and visual question answering [24].\n",
            "A wide range of works in recent times, including Alpaca [ 7], Vicuna [ 9], WizardLM [ 8] and\n",
            "Koala [14], have adopted instruction-tuning to train smaller language models with outputs\n",
            "generated from large foundation models from the GPT family. As outlined in Section 1.1,\n",
            "a significant drawback with all these works has been both limited task diversity, query\n",
            "complexity and small-scale training data in addition to limited evaluation overstating the\n",
            "benefits of such approach.\n",
            "2.2 Role of System Instructions\n",
            "Vanilla instruction-tuning (refer to Figure 4 for examples) often uses input, response pairs\n",
            "with short and terse responses. Such responses when used to train smaller models, as in\n",
            "existing works, give them limited ability to trace the reasoning process of the LFM. In\n",
            "constrast, system instructions10in recent LFMs like GPT-4 can be used to provide guidance\n",
            "9GPT-4 inference hyper-parameters in Azure OpenAI interface set as: temperature=0.7,\n",
            "top_p=0.95, frequency_penalty=0, presence_penalty=0, stop=None.\n",
            "10System instructions are part of the Chat Completion API, which is a new dedicated API for\n",
            "interacting with the ChatGPT and GPT-4 models.\n",
            "7\n",
            "----------------------------------------------------------------------------\n",
            "------------------ 1 ----------------------------------------------------\n",
            "Contents\n",
            "1 Introduction 4\n",
            "1.1 Challenges with Existing Methods . . . . . . . . . . . . . . . . . . . . . . . . 5\n",
            "1.2 Key Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n",
            "2 Preliminaries 7\n",
            "2.1 Instruction Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n",
            "2.2 Role of System Instructions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n",
            "3 Explanation Tuning 8\n",
            "3.1 Dataset Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n",
            "3.1.1 System Messages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n",
            "3.1.2 Dataset Description and Sampling from the FLAN-v2 Collection . . . 9\n",
            "3.1.3 ChatGPT as Teaching Assistant . . . . . . . . . . . . . . . . . . . . . 12\n",
            "3.2 Training . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n",
            "4 Experiment Setup 14\n",
            "4.1 Baselines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n",
            "4.2 Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n",
            "4.2.1 Open-ended Generation Capabilities . . . . . . . . . . . . . . . . . . . 15\n",
            "4.2.2 Reasoning Capabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n",
            "5 Evaluation for Open-ended Generation 17\n",
            "6 Evaluation for Reasoning 17\n",
            "6.1 AGIEval Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n",
            "6.2 Big-Bench Hard Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n",
            "7 Evaluation for Safety 23\n",
            "7.1 Truthful Question Answering . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n",
            "7.2 Toxic Content Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n",
            "7.3 Note on Hallucination and Tool Augmented LFMs . . . . . . . . . . . . . . . 27\n",
            "8 Limitations 28\n",
            "9 Conclusions 29\n",
            "10 Author Contributions 29\n",
            "11 Case Studies 30\n",
            "11.1 Trigonometric Problem Solving . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n",
            "11.2 Temporal Reasoning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n",
            "11.3 Multiple-choice Question-Answering . . . . . . . . . . . . . . . . . . . . . . . 33\n",
            "2\n",
            "----------------------------------------------------------------------------\n",
            "------------------ 2 ----------------------------------------------------\n",
            "content generation and information-seeking queries over other types of tasks. Therefore,\n",
            "models trained on such natural conversations may capture the style but not the reasoning\n",
            "process of the LFMs – demonstrated in the performance of Vicuna in Figures 2 and 3.\n",
            "Additionally, such mode of data collection is also limited in scale. Table 1 shows an overview\n",
            "of the size of data and tuning methods employed in recent popular instruction tuning works.\n",
            "Limited imitation signals. Existing methods rely on immitation learning from\n",
            "⟨query, response⟩pairs generated by the teacher model. However, this provides limited\n",
            "signals to trace the reasoning process of the teacher. Prior works [ 15,16] on open-box model\n",
            "show that richer signals such as logits, intermediate representations and attention states can\n",
            "significantly improve distillation performance. While they are not accessible for closed-box\n",
            "LFM’s7, recent work [ 17] demonstrates that richer signals like LFM rationales can help close\n",
            "the gap for task-specific distillation.\n",
            "Evaluation: Previous studies on instruction tuning of small models with LFMs are severely\n",
            "limited in their evaluation protocol. They often rely on GPT-4 for auto-evaluation by asking\n",
            "it to compare the outputs of two systems with a prompt like “given responses from system\n",
            "1 (reference) and system 2 (target), which one is better?”. However, this approach has\n",
            "several drawbacks, such as the small size of test sets (e.g., 80instructions in Vicuna and 218\n",
            "instructions in WizardLM) and the biases of GPT-4 as the judge [ 18]. For example, we notice\n",
            "that models that are instruction-tuned with GPT-4 responses tend to generate longer texts\n",
            "that GPT-4 prefers over shorter ones; as well as GPT-4 has a bias in the order of the candidate\n",
            "responses. We will show that such auto-evaluation measures overestimate the abilities of\n",
            "smaller models compared to LFMs, as the former are much weaker in comprehension and\n",
            "reasoning skills.\n",
            "1.2 Key Contributions\n",
            "In this research, our focus is on addressing the challenges mentioned above, specifically with:\n",
            "Explanation tuning: We augment⟨query, response⟩pairs with detailed responses from\n",
            "GPT-4 that explain the reasoning process of the teacher as it generates the response. These\n",
            "provide the student with additional signals for learning. We leverage system instructions (e.g..,\n",
            "explain like I’m five, think step-by-step and justify your response , etc.) to\n",
            "elicit such explanations. This is in contrast to vanilla instruction tuning, which only uses the\n",
            "prompt and the LFM response for learning, providing little opportunity for mimicking the\n",
            "LFM’s “thought” process.\n",
            "Scaling tasks and instructions: We utilize the Flan 2022 Collection [ 19] as it provides\n",
            "an extensive public assortment of tasks and instructions. Particularly, we use FLAN-\n",
            "v2, supplemented with high-quality templates, advanced formatting patterns, and data\n",
            "augmentations. Even though FLAN holds tens of millions of instructions, we selectively\n",
            "sample from the task collection to form a diverse mixture of tasks, which we then further\n",
            "sub-sample to generate complex prompts. These prompts are used to query LFMs like\n",
            "ChatGPT and GPT-4, thus creating a rich and diverse training set. We collect 5million\n",
            "ChatGPT responses, from which 1million is further sampled to acquire GPT-4 responses.\n",
            "We demonstrate how ChatGPT as a teacher assistant helps in progressive learning.\n",
            "Evaluation: We assess the generative, reasoning, and comprehension abilities of Orca, under\n",
            "a range of settings: (i) AutoEvaluation with GPT-4 on existing evaluation sets from Vicuna,\n",
            "WizardLM and the awesome prompts collection8; (ii) Academic benchmarks like Big-Bench\n",
            "Hard [4] and TruthfulQA [ 20]; (iii) Professional and Academic exams like SAT, LSAT, GRE,\n",
            "GMAT from AGIEval [ 1]; (iv) Safety evaluation with ToxiGen [ 21] to test toxic language\n",
            "generation and hate speech detection across different minority groups. Finally, we provide\n",
            "case-studies to compare the generation and reasoning abilities of Orca against OpenAI LFMs\n",
            "like ChatGPT and GPT-4, and instruction-tuned smaller model like Vicuna.\n",
            "7Note that OpenAI API’s do give access to the top-5logits for each token.\n",
            "8https://prompts.chat/\n",
            "6\n",
            "----------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using OpenAI embeddings"
      ],
      "metadata": {
        "id": "YPHryW9EhUp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get API key and create embeddings\n",
        "import os\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "openai.api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "\n",
        "from llama_index.core import Settings\n",
        "\n",
        "# global default\n",
        "Settings.embed_model = OpenAIEmbedding()"
      ],
      "metadata": {
        "id": "cIEhaffLhsoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndex.from_documents(documents)"
      ],
      "metadata": {
        "id": "grZB1o54iWoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriver_openai = index.as_retriever(similarity_top_k=3)"
      ],
      "metadata": {
        "id": "_RTUtkENrv_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_docs = retriver_openai.retrieve(\"What is instruction tuning?\")"
      ],
      "metadata": {
        "id": "JluWDrIlr1wV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.response.notebook_utils import display_source_node\n",
        "for node in similar_docs:\n",
        "  display_source_node(node)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "Mfidggh0r6jm",
        "outputId": "792549ef-6897-44a6-b8ed-1e9cbc577f61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** 2ab26823-162c-4c25-a57f-480b05f87a04<br>**Similarity:** 0.8330309385389002<br>**Text:** Model Tuning Method Data Size Teacher\nAlpaca Simple Instructions / Self-instruct 52K text-da-vinc...<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** fced3be6-00b7-4072-9dca-3faef2a3fe19<br>**Similarity:** 0.8035424483865514<br>**Text:** System instructions are sampled from a diverse instruction set including chain-of-thought\nreasoni...<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** 857f4aec-960f-4b34-ae86-74b218a94283<br>**Similarity:** 0.7809231596633633<br>**Text:** System Instruction: You are an AI assistant. User will you give you a task. Your \ngoal is to comp...<br>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,node in enumerate(similar_docs):\n",
        "  print(f\"------------------ {i} ----------------------------------------------------\")\n",
        "  print(node.text)\n",
        "  print(\"----------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rYag7L_sAf1",
        "outputId": "926f57be-6afb-4191-c762-1fec35d6fd1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------ 0 ----------------------------------------------------\n",
            "Model Tuning Method Data Size Teacher\n",
            "Alpaca Simple Instructions / Self-instruct 52K text-da-vinci-003\n",
            "Vicuna User Instructions / Natural 70K ChatGPT\n",
            "Dolly User Instructions / Natural 15K Human\n",
            "WizardLM Complex Instructions / Evol-instruct 250K ChatGPT\n",
            "Orca Complex Instructions / Explanations 5M ChatGPT (5M)\n",
            "∩GPT-4 (1M)\n",
            "Table 1: Overview of popular models instruction tuned with OpenAI large foundation models\n",
            "(LFMs). Orca leverages complex instructions and explanations for progressive learning.\n",
            "User Instruction: Use the given data to calculate the median. \n",
            "Input:[7, 3, 8, 2, 10]\n",
            "User Instruction: Answer this question.\n",
            "Input:Which small lake lies between Windermere and Grasmere?User Instruction: In this task, you will be presented with a question having \n",
            "multiple possible answers in Italian language. And you should choose a most \n",
            "suitable option out of \"A\", \"B\", \"C\", \"D\", and \"E\" based on your commonsense \n",
            "knowledge. \n",
            "Input:Solve this question: Dove non riusciresti a vedere la luce? \n",
            "Options: A scrivaniaB frigoriferoC sole D universoE atticoOutput: First, we need to arrange the data in ascending order: [2, 3, 7, 8, 10]. \n",
            "Since there are 5 numbers, the median is the middle number, which is 7.\n",
            "Output: B frigorifero\n",
            "Output: Rydal Water lies between Windermere and Grasmere.\n",
            "Figure 4: Instruction-tuning with GPT-49. Given user instructions for a task and an input,\n",
            "the system generates a response. Existing works like Alpaca [ 7], Vicuna [ 9] and variants\n",
            "follow a similar template to train small models with ⟨{user instruction, input}, output ⟩.\n",
            "2 Preliminaries\n",
            "2.1 Instruction Tuning\n",
            "Instruction tuning [ 22] is a technique that allows pre-trained language models to learn\n",
            "from input (natural language descriptions of the task) and response pairs, for example,\n",
            "{\"instruction\": \"Arrange the words in the given sentence to form a grammatically\n",
            "correct sentence.\", \"input\": \"the quickly brown fox jumped\", \"output\": \"the brown\n",
            "fox jumped quickly\"} . Instruction tuning has been applied to both language-only and\n",
            "multimodal tasks. For language-only tasks, instruction tuning has been shown to improve\n",
            "the zero-shot and few-shot performance of models such as FLAN [ 22] and InstructGPT [ 5]\n",
            "on various benchmarks. For multimodal tasks, instruction tuning has been used to generate\n",
            "synthetic instruction-following data for language-image tasks, such as image captioning [ 23]\n",
            "and visual question answering [24].\n",
            "A wide range of works in recent times, including Alpaca [ 7], Vicuna [ 9], WizardLM [ 8] and\n",
            "Koala [14], have adopted instruction-tuning to train smaller language models with outputs\n",
            "generated from large foundation models from the GPT family. As outlined in Section 1.1,\n",
            "a significant drawback with all these works has been both limited task diversity, query\n",
            "complexity and small-scale training data in addition to limited evaluation overstating the\n",
            "benefits of such approach.\n",
            "2.2 Role of System Instructions\n",
            "Vanilla instruction-tuning (refer to Figure 4 for examples) often uses input, response pairs\n",
            "with short and terse responses. Such responses when used to train smaller models, as in\n",
            "existing works, give them limited ability to trace the reasoning process of the LFM. In\n",
            "constrast, system instructions10in recent LFMs like GPT-4 can be used to provide guidance\n",
            "9GPT-4 inference hyper-parameters in Azure OpenAI interface set as: temperature=0.7,\n",
            "top_p=0.95, frequency_penalty=0, presence_penalty=0, stop=None.\n",
            "10System instructions are part of the Chat Completion API, which is a new dedicated API for\n",
            "interacting with the ChatGPT and GPT-4 models.\n",
            "7\n",
            "----------------------------------------------------------------------------\n",
            "------------------ 1 ----------------------------------------------------\n",
            "System instructions are sampled from a diverse instruction set including chain-of-thought\n",
            "reasoning steps, explain like I’m five, being helpful and informative, etc. Such rich and\n",
            "well-structured response allows tuning small models to mimic the thinking process of GPT-4\n",
            "on⟨{system instruction, user instruction, input}, output ⟩pairs.\n",
            "to the model on how to behave and respond. They are written in natural language and\n",
            "separated from the user messages by using the role of “system” in the JSON request. System\n",
            "instructions can specify the tone, task, format, and limitations of the model’s responses.\n",
            "System instructions are also a way of improving the safety of model responses. For example,\n",
            "a set of system instructions designed for safety harness could be:\n",
            "•The assistant must not generate harmful or offensive content.\n",
            "•The assistant must respect the privacy and consent of the user.\n",
            "•The assistant must acknowledge its limitations and uncertainties.\n",
            "3 Explanation Tuning\n",
            "To address the shortcomings of existing works, we tap into large-scale training data with\n",
            "diverse tasks augmented with complex instructions and rich signals. Specifically, our data\n",
            "contains human and augmented system instructions for a large collection of tasks sampled\n",
            "from FLAN-v2 (aka Flan 2022) [ 19]. Given the large size of the FLAN-v2 collection and\n",
            "varying number of examples for constituent datasets and tasks, we sample from a mixture of\n",
            "tasks from different categories (described in the next section) to create our training data.\n",
            "3.1 Dataset Construction\n",
            "Each instance in our training data consists of the following triple: ⟨System message, User\n",
            "query, LFM response ⟩. Thesystem message , placed at the start of the prompt, provides\n",
            "the LFM with essential context, guidelines, and other pertinent details. We leverage the\n",
            "system message to vary the length of the response; outline the assistant’s character; establish\n",
            "acceptable and non-acceptable LFM behavior; and determine the structure of the agent’s\n",
            "response. The user query defines the actual task we want the LFM to perform. To obtain\n",
            "a large and diverse set of user queries we utilize the FLAN-v2 collection [ 19]. We sample 5\n",
            "million user queries from FLAN-v2 for which we collect ChatGPT responses. We further\n",
            "sample 1million instructions from the 5million set for which we collect GPT-4 responses.\n",
            "All the queries to the agents are augmented with system instructions, as outlined below.\n",
            "8\n",
            "----------------------------------------------------------------------------\n",
            "------------------ 2 ----------------------------------------------------\n",
            "System Instruction: You are an AI assistant. User will you give you a task. Your \n",
            "goal is to complete the task as faithfully as you can. While performing the task \n",
            "think step-by-step and justify your steps.\n",
            "User Instruction: Use the given data to calculate the median.\n",
            "Input:[7, 3, 8, 2, 10]\n",
            "System Instruction: You are an AI assistant. User will you give you a task. Your \n",
            "goal is to complete the task as faithfully as you can. While performing the task \n",
            "think step-by-step and justify your steps.\n",
            "User Instruction: Answer this question.\n",
            "Input:Which small lake lies between Windermere and Grasmere?System Instruction: You are an AI assistant. Provide a detailed answer so user \n",
            "don't need to search outside to understand the answer.\n",
            "User Instruction: In this task, you will be presented with a question having \n",
            "multiple possible answers in Italian language. And you should choose a most \n",
            "suitable option out of \"A\", \"B\", \"C\", \"D\", and \"E\" based on your commonsense \n",
            "knowledge. \n",
            "Input:Solve this question: Dove non riuscirestia vedere la luce? \n",
            "Options: A scrivaniaB frigoriferoC sole D universoE atticoOutput: To calculate the median, I will follow these steps:\n",
            "Step 1: Arrange the data in ascending order [2, 3, 7, 8, 10]\n",
            "Step 2: Determine if the data set has an odd or even number of values\n",
            "The data set has 5 values, which is an odd number.\n",
            "Step 3: Find the middle value\n",
            "Since the data set has an odd number of values, the median is the middle \n",
            "value in the ordered list. The middle value in the list [2, 3, 7, 8, 10] is 7.\n",
            "Output: Based on the given options and the context of the question, \"Dove \n",
            "non riusciresti a vedere la luce?\" (Where would you not be able to see \n",
            "light?), the most suitable answer would be:B frigorifero(refrigerator). \n",
            "This is because when the refrigerator door is closed, you would not be able \n",
            "to see the light inside it. In the other options, light is generally visible or \n",
            "present:\n",
            "A scrivania(desk) -Light is usually present around a desk. \n",
            "C sole (sun) -The sun is the primary source of light in our solar system.\n",
            "D universo(universe) -Light is present throughout the universe in the form \n",
            "of stars, galaxies, etc.\n",
            "E attico(attic) -Attics typically have windows or other sources of light, \n",
            "making it possible to see light there.\n",
            "Output: To answer this question, I will search for information about the small \n",
            "lake located between Windermere and Grasmere.\n",
            "Step 1: Identify the location of Windermere and Grasmere. They are both \n",
            "located in the Lake District National Park, in the county of Cumbria, England.\n",
            "Step 2: Research the lakes in the Lake District. The Lake District is known for \n",
            "its many lakes, so I will look for a list of lakes in the area and their locations in \n",
            "relation to Windermere and Grasmere.\n",
            "Step 3: Find the small lake between Windermere and Grasmere. \n",
            "After researching the lakes in the Lake District, I found that Rydal Water is a \n",
            "small lake situated between Windermere and Grasmere.Figure 5: Explanation-tuning with GPT-4. In addition to user instructions and input, system\n",
            "instructions are provided to guide the system to form a well-reasoned and cogent response.\n",
            "System instructions are sampled from a diverse instruction set including chain-of-thought\n",
            "reasoning steps, explain like I’m five, being helpful and informative, etc. Such rich and\n",
            "well-structured response allows tuning small models to mimic the thinking process of GPT-4\n",
            "on⟨{system instruction, user instruction, input}, output ⟩pairs.\n",
            "to the model on how to behave and respond. They are written in natural language and\n",
            "separated from the user messages by using the role of “system” in the JSON request. System\n",
            "instructions can specify the tone, task, format, and limitations of the model’s responses.\n",
            "System instructions are also a way of improving the safety of model responses. For example,\n",
            "a set of system instructions designed for safety harness could be:\n",
            "•The assistant must not generate harmful or offensive content.\n",
            "•The assistant must respect the privacy and consent of the user.\n",
            "•The assistant must acknowledge its limitations and uncertainties.\n",
            "----------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similar_docs1 = retriver.retrieve(\"What is orca?\")\n",
        "from llama_index.core.response.notebook_utils import display_source_node\n",
        "for node in similar_docs1:\n",
        "  display_source_node(node)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "bYjKKHGetTXs",
        "outputId": "252d1850-8d3a-4de6-8b52-4cf46a3bd1e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** 144c4c2e-681f-444d-bd3f-98b745b28c06<br>**Similarity:** 0.6652078795266653<br>**Text:** For Vicuna and Orca the format of the prompt is as follows:\n### System:\n### Human:\nQ: Which blood...<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** 98e45e23-9d19-4e6a-bc0e-adcd2561e554<br>**Similarity:** 0.6508155769295554<br>**Text:** Task / System Message Empty Follow Well Detailed Answer\nAQuA-RAT 27.9 21.3 25.2\nLogiQA 35.2 36.4 ...<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** cbd45178-6472-4bbe-b435-78ebf64e2ad3<br>**Similarity:** 0.6503899050959893<br>**Text:** 0102030405060708090AQuA-RAT (GRE Math, GMAT Math)\nLogiQA (English, Civil Services)\nLSAT-AR\nLSAT-L...<br>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,node in enumerate(similar_docs1):\n",
        "  print(f\"------------------ {i} ----------------------------------------------------\")\n",
        "  print(node.text)\n",
        "  print(\"----------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-OME8m4te4F",
        "outputId": "0bc6395a-1773-4670-f9eb-cd3d1f14296f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------ 0 ----------------------------------------------------\n",
            "For Vicuna and Orca the format of the prompt is as follows:\n",
            "### System:\n",
            "### Human:\n",
            "Q: Which blood type makes the best CEOs? Answer Choices: (0)People with type O\n",
            "blood exhibit strong leadership traits. (1)Blood type has no impact on someone’s\n",
            "abilities. (2)People with type O blood make the best leaders. (3)The best CEOs have\n",
            "type O blood. A: Among 0 through 3, the answer is\n",
            "### Assistant:\n",
            "Figure 13: Prompt format for Vicuna and Orca used in all multiple choice-question answering\n",
            "tasks including TruthfulQA-MC and those in AGIEval and Big-Bench Hard.\n",
            "Evaluation results: From Figure 14, we observe that Orca’s outputs are significantly more\n",
            "truthful than Vicuna-13B; while trailing behind ChatGPT and GPT-4.\n",
            "Instruction following results: Vicuna output format is quite noisy in general – as it often\n",
            "does not follow the prompt template – compared to Orca, ChatGPT and GPT-4 which took\n",
            "us significantly more time to manually label its outputs. In Figure 15 we present the rate of\n",
            "failure of different models to follow the requested format of the prompt for different models\n",
            "in the dataset.\n",
            "GPT-4 ChatGPT Orca 13B Vicuna 13B020406080100AccuracyTruthful QA MC\n",
            "GPT-4\n",
            "ChatGPT\n",
            "Orca 13B\n",
            "Vicuna 13B\n",
            "Figure 14: Performance of different models on TruthfulQA. While Orca performs significantly\n",
            "better than Vicuna there is still a gap between Orca and ChatGPT and GPT-4.\n",
            "GPT-4 ChatGPT Orca 13B Vicuna 13B020406080100Rate of FailureIntruction Following in Truthful QA MC\n",
            "GPT-4\n",
            "ChatGPT\n",
            "Orca 13B\n",
            "Vicuna 13B\n",
            "Figure 15: Failure rate (lower the better) of different models in instruction following for\n",
            "TruthfulQA. Vicuna has a significant gap with Orca, ChatGPT and GPT-4.\n",
            "24\n",
            "----------------------------------------------------------------------------\n",
            "------------------ 1 ----------------------------------------------------\n",
            "Task / System Message Empty Follow Well Detailed Answer\n",
            "AQuA-RAT 27.9 21.3 25.2\n",
            "LogiQA 35.2 36.4 37.2\n",
            "LSAT-AR 21.3 19.6 20.9\n",
            "LSAT-LR 43.9 44.3 44.3\n",
            "LSAT-RC 57.3 60.2 61.7\n",
            "SAT-Math 32.3 27.3 30\n",
            "SAT-English 76.7 73.8 74.3\n",
            "SAT-English (w/o Psg.) 38.8 39.3 38.8\n",
            "Average 41.7 40.3 41.6\n",
            "Table 9: Zero-shot performance comparison of Orca with different system messages in\n",
            "AGIEval benchmark on multiple-choice English questions. The system messages and their\n",
            "identifiers from Table 2 correspond to <empty system message> (Id. 1), follow well (Id. 5)\n",
            "and detailed answer (Id. 2). Considering the performance with the best system instruction\n",
            "for each task, Orca has a performance gap of 4.4pts against ChatGPT.\n",
            "Task / Model Orca Orca-FLAN-1M (GPT-4 only)\n",
            "AQuA-RAT 27.9 21.65\n",
            "LogiQA 35.2 31.95\n",
            "LSAT-AR 21.3 18.7\n",
            "LSAT-LR 43.9 41.76\n",
            "LSAT-RC 57.3 51.67\n",
            "SAT-Math 32.3 26.82\n",
            "SAT-English 76.7 68.45\n",
            "SAT-English (w/o Psg.) 38.8 36.41\n",
            "Average 41.7 37.18\n",
            "Table 10: Zero-shot performance comparison of Orca trained on FLAM-5M (ChatGPT) and\n",
            "FLAN-1M (GPT-4), vs Orca trained only on FLAN-1M (GPT-4) in AGIEval benchmark on\n",
            "multiple-choice English questions.\n",
            "Analysis of 100 random ChatGPT-beats-Orca and Orca-beats-ChatGPT samples:\n",
            "•Domain knowledge: Models require specialized domain knowledge to solve some of\n",
            "the problems such as Tesla batteries, concepts from Chemistry, etc. 15% and 21% of the\n",
            "ChatGPT-beats-Orca and Orca-beats-ChatGPT examples respectively fall under this\n",
            "category.\n",
            "•Complex reasoning: Some examples require complex reasoning such as reasoning about\n",
            "more than five objects/persons. For example, the logical reasoning question that starts\n",
            "with “There are 6 rectangular vegetable ponds of the same size in a plastic shed, arranged\n",
            "in order from left to right? ” requires the model to capture spatial relationships of six\n",
            "ponds and perform spatial reasoning. 14% and 18% of the ChatGPT-beats-Orca and\n",
            "Orca-beats-ChatGPT examples respectively fall under complex reasoning category.\n",
            "•Long context: Some examples have long context (e.g., passage containing several\n",
            "paragraphs of text), which require reasoning over long spans of text. 16% of ChatGPT-\n",
            "beats-Orca examples have long context, while context of only 8% of Orca-beats-ChatGPT\n",
            "examples are long. This result highlights that ChatGPT has an edge over Orca in\n",
            "modeling long contexts.\n",
            "•Geometric reasoning: Examples such as “ The ratio of the volumes of a cube to that of\n",
            "the sphere which will fit inside the cube is? ” require reasoning about geometric objects.\n",
            "2% and 5% of the ChatGPT-beats-Orca and Orca-beats-ChatGPT examples respectively\n",
            "fall under this category, indicating the performance gap in geometric reasoning between\n",
            "the two models.\n",
            "19\n",
            "----------------------------------------------------------------------------\n",
            "------------------ 2 ----------------------------------------------------\n",
            "0102030405060708090AQuA-RAT (GRE Math, GMAT Math)\n",
            "LogiQA (English, Civil Services)\n",
            "LSAT-AR\n",
            "LSAT-LR\n",
            "LSAT-RC SAT-MathSAT-EnglishSAT-English (w/o Psg.)Human Avg. ChatGPT GPT-4 Orca-13BFigure 11: Topical breakdown in performance of GPT-4, ChatGPT and Orca in the AGIEval\n",
            "benchmark on professional and academic exams.\n",
            "•LaTeX reasoning: Some examples have LaTeX typesetting in the question, which\n",
            "requires understanding of LaTeX symbols for solving these examples. For example, “ A\n",
            "line in the $x y$-plane passes through the origin and has a slope of $\\frac{1}{7}$. Which\n",
            "of the following points lies on the line? ” requires processing the fraction operator. 2%\n",
            "and 10% of the ChatGPT-beats-Orca and Orca-beats-ChatGPT examples respectively\n",
            "fall under this category.\n",
            "6.2 Big-Bench Hard Results\n",
            "Table 11 shows the zero-shot performance comparison of Orca against baseline models on\n",
            "Big-Bench Hard with standard zero-shot prompting (no exemplars, no CoT). Orca performs\n",
            "marginally better than ChatGPT on aggregate across all tasks; significantly lags\n",
            "GPT-4; and outperforms Vicuna by 113%.Similar to AGIEval, Vicuna performs poorly\n",
            "on sophisticated reasoning tasks in this benchmark.\n",
            "While significantly better than Vicuna and marginally better than ChatGPT, Orca’s average\n",
            "performance of 49.7%, lags GPT-4 by 26%. Note that GPT-4 has reported a data contami-\n",
            "nation issue with Big-Bench and that we are not aware of such issues with either LLaMA’s\n",
            "training data (the base model used by both Vicuna and Orca) or the Flan-V2 collection or\n",
            "Vicuna’s training data (ShareGPT).\n",
            "Given the close performance on average on BigBench-Hard, we take a deeper look at\n",
            "differences in performance between Orca and ChatGPT:\n",
            "Entailment and Semantic Understanding :\n",
            "•Orca performs better at entailment (formal fallacies) and semantic understanding (Dis-\n",
            "ambiguation QA and Snarks).\n",
            "•In the formal fallacies task, a model has to determine whether a given argument can\n",
            "be logically deduced from a set of statements, Orca achieves 4.5%improvement over\n",
            "ChatGPT on this task.\n",
            "20\n",
            "----------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ragatouille"
      ],
      "metadata": {
        "id": "psZf2S9L1aPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.llama_pack import download_llama_pack\n",
        "RAGatouille_retriever = download_llama_pack(\"RAGatouilleRetrieverPack\",\"./ragatouille_pack\")"
      ],
      "metadata": {
        "id": "-ODJJM1V1clg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ragatouille_pack = RAGatouille_retriever(documents,\n",
        "                                         index_name=\"orca\",\n",
        "                                         top_k=3,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5f6f9d04fcb34f268ec31a070aaf6bb0",
            "0a6634c0145e446ba07bfce9903adfd4",
            "60abc1bb2f614ccca29d31794e2aeb46",
            "4ad671b44be0438390a766dd35484c2d",
            "93b9b66818734e4faf2b3222d91cfb7e",
            "972dc0692ee44846bb1f3f132400ee92",
            "92fa8077a55b4e3a9ece61cd251cde56",
            "c1d05a90aaf44ae2bae0b3dbc2119d7c",
            "4584ee9bd0724544b27f7de4a3943d53",
            "31c14c1de1cb4e269f468a6416f438b9",
            "b64e52a6bc0043f5aaaea4ad625e028e",
            "019ed65d4c5c4d2f9d8200cba1db6c36",
            "3b148db5df0e404f821a2d5020c8df11",
            "854ed825f7f143d595fb2f875af18482",
            "0c0b08c33c1d4aa7b5963889da3c6182",
            "22e3e0e33fe542d4a2eb767ae500892a",
            "6841d2d78f464cd1b0e31d40986e9c17",
            "fe6cf2d61f31447bba5189a339e47903",
            "0590d0ca08484d3e8f61f01c5e7c849e",
            "64199877582649529680519152c17d06",
            "859b3c79e4b14696ada7f80794270dfa",
            "750ed0beb396436bba2fa2bf518400cf",
            "24bb7d3e4ad24c4fa8935cc280439c22",
            "73b49e3b7c6545318b90ebff94eb1196",
            "b74028c063584b6291d20e043e247053",
            "fc3d23b79b904ef48a637eedd15bc526",
            "297d33ae48f2477a8e4ba06e6ccd0e89",
            "6966dfa918bd41eeac255720906893be",
            "dd5bbbdbd5da4a1ebc7908345c2be159",
            "90fcca5e6805490788d4c681ded61993",
            "677aef653cbc4cd8833065391362aafb",
            "97847a7cf06441699aea11b5684a6821",
            "65fecea47aab4d27b6c9fa5b1feff2e6",
            "1a6fe5b34ebc44d5ab9020a650d66c08",
            "1acd52edd1ee4ae0b18ec21c15541227",
            "1758cc64c1d0485ea21869688e82a500",
            "56f5ca57140e4f678595102351950e73",
            "e6c157a04d13485dbfd0ab820384d3ad",
            "1827ed49676e43018d983f4a718129df",
            "1d44298a25e645a48331f90afedf6f7a",
            "723be54aa3c04e558d34a4423430a347",
            "7453fee093b34c3badc387b6cbabbcdc",
            "ec9bd6d48bca4b46aca44926cb5c6237",
            "4a1404dadcfd4370988dce8b1f5181ad",
            "2e5ce35143e1459783b633558b86ee0a",
            "74e0b1abc9a04438842c13d7b53e7adb",
            "8ef6da09ff014c21a75bb3b665603d8b",
            "827276dec42d4114863e22f780a7ec2a",
            "b5f4c7dfa8b144818a560ed498c80a0e",
            "d74ec5f8190e44479c19579fca269194",
            "afb8dce0b66c4ac9bae30af6e38dfc2a",
            "5201baa14e874cc8bdb09f7efb35fe26",
            "58d9f21552d847199fff3f3a3cbcb65e",
            "1c6a82a2b3c949fc9c87342e3d909134",
            "8f5963127ab8473998b51127b11d2224",
            "f48b3bae4ddc4454be9bee98e9384c49",
            "348757a7be634333855de66b879959ea",
            "5f20d410f021400a8e8e8dc71246f4c0",
            "c5f9629b7b7641c5b1d48def3852581e",
            "0974088c8d114d2b93d8d3aeb86d9b3f",
            "0b0eae06417b4c5fb53615c9c8cc0299",
            "e6ac854eb0d646c98a1088003303c682",
            "b73eca0fb3014138a2717b7770b6a371",
            "673ff1dbb519492a91bef1b2ff5ae0f9",
            "fa793faaf21849ab842cd670ae8d618d",
            "10e91ddb3acb48289d34a48e8c167b3b",
            "4b5f76d849b5443e9d2d12e73e98c142",
            "c59db7bb402240498d9bd06426d76ec7",
            "90f929e022424772920d0ea3a23eebba",
            "4b7267e0994349969498236737ea5d06",
            "0ac1d9a0627b4038b67e0f239489b0b8",
            "959a5c46e66e47828fb2ee8127926959",
            "f60fa66de69249b3b139f3ecc535bf78",
            "5271ee2578a14c4b804d1869d96fbd6a",
            "736f630bc0f54fb0a12204f66d8ac31c",
            "38544423f3884bcbb5d0444ebfa28a96",
            "69c52b232e384775a2cb73db36b9c767"
          ]
        },
        "id": "6IjR-zx5160E",
        "outputId": "12c24e07-293f-46eb-a0de-199d1acce603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "artifact.metadata:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f6f9d04fcb34f268ec31a070aaf6bb0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "019ed65d4c5c4d2f9d8200cba1db6c36"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24bb7d3e4ad24c4fa8935cc280439c22"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/405 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a6fe5b34ebc44d5ab9020a650d66c08"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e5ce35143e1459783b633558b86ee0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f48b3bae4ddc4454be9bee98e9384c49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b5f76d849b5443e9d2d12e73e98c142"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Apr 21, 08:51:01] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
            "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
            "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
            "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
            "--------------------\n",
            "\n",
            "\n",
            "[Apr 21, 08:51:37] #> Creating directory .ragatouille/colbert/indexes/orca \n",
            "\n",
            "\n",
            "[Apr 21, 08:51:38] [0] \t\t #> Encoding 219 passages..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/7 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|██████████| 7/7 [03:28<00:00, 29.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Apr 21, 08:55:06] [0] \t\t avg_doclen_est = 155.7305908203125 \t len(local_sample) = 219\n",
            "[Apr 21, 08:55:07] [0] \t\t Creating 2,048 partitions.\n",
            "[Apr 21, 08:55:07] [0] \t\t *Estimated* 34,104 embeddings.\n",
            "[Apr 21, 08:55:07] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/orca/plan.json ..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "used 20 iterations (33.8816s) to cluster 32400 items into 2048 clusters\n",
            "[0.033, 0.037, 0.033, 0.032, 0.032, 0.035, 0.036, 0.032, 0.033, 0.035, 0.032, 0.034, 0.031, 0.035, 0.034, 0.034, 0.03, 0.034, 0.031, 0.035, 0.033, 0.035, 0.032, 0.034, 0.032, 0.033, 0.035, 0.034, 0.034, 0.036, 0.033, 0.035, 0.035, 0.033, 0.034, 0.03, 0.037, 0.032, 0.034, 0.037, 0.037, 0.034, 0.034, 0.035, 0.034, 0.031, 0.033, 0.038, 0.034, 0.034, 0.033, 0.034, 0.034, 0.033, 0.032, 0.034, 0.036, 0.035, 0.037, 0.032, 0.033, 0.036, 0.035, 0.035, 0.036, 0.035, 0.035, 0.035, 0.034, 0.033, 0.037, 0.033, 0.034, 0.035, 0.035, 0.035, 0.035, 0.035, 0.035, 0.038, 0.036, 0.035, 0.035, 0.037, 0.033, 0.032, 0.034, 0.035, 0.031, 0.038, 0.035, 0.036, 0.033, 0.035, 0.034, 0.031, 0.036, 0.032, 0.035, 0.033, 0.033, 0.036, 0.033, 0.034, 0.035, 0.032, 0.034, 0.032, 0.032, 0.031, 0.034, 0.036, 0.035, 0.032, 0.035, 0.032, 0.034, 0.033, 0.033, 0.036, 0.032, 0.033, 0.033, 0.035, 0.034, 0.035, 0.034, 0.031]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Apr 21, 08:55:41] [0] \t\t #> Encoding 219 passages..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 14%|█▍        | 1/7 [00:31<03:06, 31.01s/it]\u001b[A\n",
            " 29%|██▊       | 2/7 [01:07<02:50, 34.01s/it]\u001b[A\n",
            " 43%|████▎     | 3/7 [01:34<02:03, 30.93s/it]\u001b[A\n",
            " 57%|█████▋    | 4/7 [02:03<01:30, 30.03s/it]\u001b[A\n",
            " 71%|███████▏  | 5/7 [02:30<00:58, 29.28s/it]\u001b[A\n",
            " 86%|████████▌ | 6/7 [03:02<00:29, 29.92s/it]\u001b[A\n",
            "100%|██████████| 7/7 [03:26<00:00, 29.53s/it]\n",
            "1it [03:28, 208.76s/it]\n",
            "100%|██████████| 1/1 [00:00<00:00, 868.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Apr 21, 08:59:09] #> Optimizing IVF to store map from centroids to list of pids..\n",
            "[Apr 21, 08:59:09] #> Building the emb2pid mapping..\n",
            "[Apr 21, 08:59:09] len(emb2pid) = 34105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 2048/2048 [00:00<00:00, 46745.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Apr 21, 08:59:10] #> Saved optimized IVF to .ragatouille/colbert/indexes/orca/ivf.pid.pt\n",
            "Done indexing!\n",
            "LLM is explicitly disabled. Using MockLLM.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.response.notebook_utils import display_source_node\n",
        "\n",
        "retriever = ragatouille_pack.get_modules()[\"retriever\"]\n",
        "nodes = retriever.retrieve(\"What is instruction tuning?\")\n",
        "\n",
        "for node in nodes:\n",
        "    display_source_node(node)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "wuVFjzvn2dFi",
        "outputId": "5200abab-5c24-454c-d17d-cbae9f60bf4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading searcher for index orca for the first time... This may take a few seconds\n",
            "[Apr 21, 08:59:22] #> Loading codec...\n",
            "[Apr 21, 08:59:22] #> Loading IVF...\n",
            "[Apr 21, 08:59:22] Loading segmented_lookup_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Apr 21, 08:59:53] #> Loading doclens...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 3591.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Apr 21, 08:59:53] #> Loading codes and residuals...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 205.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Apr 21, 08:59:53] Loading filter_pids_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Apr 21, 09:00:24] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
            "Searcher loaded!\n",
            "\n",
            "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
            "#> Input: . What is instruction tuning?, \t\t True, \t\t None\n",
            "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  7899, 17372,  1029,   102,   103,   103,\n",
            "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
            "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
            "          103,   103])\n",
            "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** 6f94ba79-81cd-47a4-b777-ab01921fa54f<br>**Similarity:** 26.51420021057129<br>**Text:** Given user instructions for a task and an input,\nthe system generates a response. Existing works ...<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** bb290fd0-7937-46c2-bd9a-fed687471792<br>**Similarity:** 26.102283477783203<br>**Text:** For multimodal tasks, instruction tuning has been used to generate\nsynthetic instruction-followin...<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Node ID:** 9e168d49-957f-42b4-853c-72b1ed984e25<br>**Similarity:** 21.646852493286133<br>**Text:** For example, we notice\nthat models that are instruction-tuned with GPT-4 responses tend to genera...<br>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,node in enumerate(nodes):\n",
        "  print(f\"------------------ {i} ----------------------------------------------------\")\n",
        "  print(node.text)\n",
        "  print(\"----------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OWKmU3j3VAw",
        "outputId": "c30fe685-8f5e-43fe-faa4-d1b7dbe3b61e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------ 0 ----------------------------------------------------\n",
            "Given user instructions for a task and an input,\n",
            "the system generates a response. Existing works like Alpaca [ 7], Vicuna [ 9] and variants\n",
            "follow a similar template to train small models with ⟨{user instruction, input}, output ⟩.\n",
            "2 Preliminaries\n",
            "2.1 Instruction Tuning\n",
            "Instruction tuning [ 22] is a technique that allows pre-trained language models to learn\n",
            "from input (natural language descriptions of the task) and response pairs, for example,\n",
            "{\"instruction\": \"Arrange the words in the given sentence to form a grammatically\n",
            "correct sentence.\", \"input\": \"the quickly brown fox jumped\", \"output\": \"the brown\n",
            "fox jumped quickly\"} . Instruction tuning has been applied to both language-only and\n",
            "multimodal tasks. For language-only tasks, instruction tuning has been shown to improve\n",
            "the zero-shot and few-shot performance of models such as FLAN [ 22] and InstructGPT [ 5]\n",
            "on various benchmarks. For multimodal tasks, instruction tuning has been used to generate\n",
            "synthetic instruction-following data for language-image tasks, such as image captioning [ 23]\n",
            "and visual question answering [24].\n",
            "----------------------------------------------------------------------------\n",
            "------------------ 1 ----------------------------------------------------\n",
            "For multimodal tasks, instruction tuning has been used to generate\n",
            "synthetic instruction-following data for language-image tasks, such as image captioning [ 23]\n",
            "and visual question answering [24].\n",
            "A wide range of works in recent times, including Alpaca [ 7], Vicuna [ 9], WizardLM [ 8] and\n",
            "Koala [14], have adopted instruction-tuning to train smaller language models with outputs\n",
            "generated from large foundation models from the GPT family. As outlined in Section 1.1,\n",
            "a significant drawback with all these works has been both limited task diversity, query\n",
            "complexity and small-scale training data in addition to limited evaluation overstating the\n",
            "benefits of such approach.\n",
            "2.2 Role of System Instructions\n",
            "Vanilla instruction-tuning (refer to Figure 4 for examples) often uses input, response pairs\n",
            "with short and terse responses. Such responses when used to train smaller models, as in\n",
            "existing works, give them limited ability to trace the reasoning process of the LFM.\n",
            "----------------------------------------------------------------------------\n",
            "------------------ 2 ----------------------------------------------------\n",
            "For example, we notice\n",
            "that models that are instruction-tuned with GPT-4 responses tend to generate longer texts\n",
            "that GPT-4 prefers over shorter ones; as well as GPT-4 has a bias in the order of the candidate\n",
            "responses. We will show that such auto-evaluation measures overestimate the abilities of\n",
            "smaller models compared to LFMs, as the former are much weaker in comprehension and\n",
            "reasoning skills.\n",
            "1.2 Key Contributions\n",
            "In this research, our focus is on addressing the challenges mentioned above, specifically with:\n",
            "Explanation tuning: We augment⟨query, response⟩pairs with detailed responses from\n",
            "GPT-4 that explain the reasoning process of the teacher as it generates the response. These\n",
            "provide the student with additional signals for learning. We leverage system instructions (e.g..,\n",
            "explain like I’m five, think step-by-step and justify your response , etc.) to\n",
            "elicit such explanations. This is in contrast to vanilla instruction tuning, which only uses the\n",
            "prompt and the LFM response for learning, providing little opportunity for mimicking the\n",
            "LFM’s “thought” process.\n",
            "----------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing ColBert In Langchain"
      ],
      "metadata": {
        "id": "WvTx5fx2JjiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ragatouille import RAGPretrainedModel\n",
        "from langchain_community.document_loaders import PyPDFLoader\n"
      ],
      "metadata": {
        "id": "G7UhsV8WJoGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RAG = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296,
          "referenced_widgets": [
            "363892c16afc4ff69c0b2386aed20480",
            "685da684f5d64f40bcfbe1a5c2e9937e",
            "b47447eec06c4a20ba4a2b7aa6fc7076",
            "68450ab5f1e64bf096fcbba1b579d962",
            "eab7c71c4aef4e53a96796ad1609b96c",
            "4c94931c5e9e47c38a15381527f99fdb",
            "4cdb20077f4d4055b088ec794b597ff4",
            "4e699957e2aa4ea4bb610f5d302e5f52",
            "ae5ab13ae07c4bac9cfaa56fd2b06545",
            "a70e6ab0513943739c6d636d2857bd17",
            "454939afd6914f658170e0664db35975",
            "56042d89e5034c3592793ed63e703c5a",
            "db1fd8d168d846c19a1c8a88d6babdff",
            "e00363f29ff3485e97434d34385c7b03",
            "0f7f8683d03b48df9175d2e8ec895503",
            "f94ce0f19191443ead21a69607068b96",
            "ac344d33917c419ca4873ae9518bbf93",
            "e81eac2dbc2b4b40bf232d957e590b92",
            "f9dbbd290e89493c81525ce31ea189d5",
            "d78968a8cb694fb4947c8e8e7ead44a3",
            "174d3b5e6d50403a9adf760ddeb9c64c",
            "d4e4d35682fe4166812b71f95ae6aa5b",
            "9702bf17af684e948886e4416227bf04",
            "d2fad5676786497f8cb2b3923a80479f",
            "c366849fd1ad4e0980a1603086b5f660",
            "3d558c422e574cecb25911c4d8c2def1",
            "a612195ccefa44f58bd8704be4944f8d",
            "f5b387899b6245c9a4b90ce7b1ba0653",
            "ac907a44f1314996ba8c5a46c173f489",
            "55b30692030848c0b12e1f3e1abe12ff",
            "01992549e3e24725bb4728556911ba07",
            "c81190bb7e5a4e8a8829f3728031508a",
            "a522af96819742be9f72a68fe1ff0018",
            "aa0be30c32d24052a8c1e18a46afb892",
            "780678f132e2467d93518b1976278525",
            "a4d2036bd4d6471b8f1a53a09f5c73a5",
            "046f3e1bb58948378e4662d74ac2a157",
            "757d9bf337434e0da8ceb279e992c63b",
            "0a26530b198e4fcaabfd27a41fe91297",
            "04637f70e3cb46239919c7a548e77fcf",
            "80ce0fa84a784559acf994a5e0e12711",
            "fec920793dd84e609dce910ca317e96e",
            "731466317d64474ba4b5564e6dfdd5fd",
            "fc63be73435c44f9ab0808504774400e",
            "55cc5ea7cf104730b33d32f69c1b8d61",
            "54c41b3cc1c64c85afff10a29e52f81e",
            "f529abd39a884c15bac0542fd5aec1e4",
            "aee19a7a11824487b80668ed9bf55b22",
            "b870baedefc34221a1fe37a985a1e42d",
            "ab3be5da2be049829747a4f21ffb1808",
            "a552cfdc183045d1a003f66328ec1348",
            "621103b3cc7f4ce5986d2819d224ee4e",
            "11e5e8e94e784b4b8fe43fed8bd60a28",
            "4e37dd9e5b264374be5f1127f3972d1b",
            "010153f29dbc47da99a87e36db559802",
            "cd5640c7a9fe43009eb1abd29fc1335c",
            "2befdf2448e14b3d957e086c3b333216",
            "6823425fa66a4170ac037942cfdfd66d",
            "0ec10b754ba7405bbdef7d5580f17c79",
            "8c7c9073e6b848e1ad8a5095e1879ee3",
            "a5eefbdd09014d34848dbe690d98ecc0",
            "de95baef449d42d79ab4172dfa60efe1",
            "18c91d04bcf7484f914403dffff03d21",
            "6188f31fef9440138f8519637998793c",
            "c5ba7160bee14750aaaea60b0b30d643",
            "a44ef52b015440e184b09232373ed9c1",
            "120d40218b614594ae29f7c50dfe028e",
            "6512786a54da43eeaac0fc79c64862b0",
            "f94e2a16be1d4d2d9f47defbfb9876f4",
            "9c276bd8eb1f4934a6848de6f9356214",
            "7a81cbf226fe4934aa0a2193de741834",
            "98e023150de0463cb74594b04c8562f5",
            "dc61936f6ef3452fa5523e56807a2a27",
            "60b831fddbb744a3b22a8b5b2ac9e13e",
            "421e2d05c26a4e7389534d0c852a0e71",
            "0154058a0bb9430386bf26e22a3fb2d7",
            "f139c959577544988eb9579538245443"
          ]
        },
        "id": "gio6tHw7J-Hf",
        "outputId": "97013dc4-d0e0-433a-f903-7fddc9400491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "artifact.metadata:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "363892c16afc4ff69c0b2386aed20480"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56042d89e5034c3592793ed63e703c5a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9702bf17af684e948886e4416227bf04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/405 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa0be30c32d24052a8c1e18a46afb892"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55cc5ea7cf104730b33d32f69c1b8d61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd5640c7a9fe43009eb1abd29fc1335c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "120d40218b614594ae29f7c50dfe028e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Apr 28, 14:44:56] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Document"
      ],
      "metadata": {
        "id": "_G2LxQjqKq23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaders = PyPDFLoader(\"/content/2306.02707.pdf\")\n",
        "pages = loaders.load()\n",
        "print(len(pages))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5qR-m_sKlnG",
        "outputId": "d93b0a0a-f2de-41ba-a2d5-4f5228c01f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_document = \"\"\n",
        "for page in pages:\n",
        "  full_document += page.page_content"
      ],
      "metadata": {
        "id": "CoWhLTDXLBON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Index"
      ],
      "metadata": {
        "id": "933OoHvvLLs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RAG.index(collection=[full_document],\n",
        "          index_name=\"orca_paper\",\n",
        "          max_document_length=512,\n",
        "          split_documents=True,\n",
        "          use_faiss=True\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "lEOYoquMLKLN",
        "outputId": "2dd410e8-8de7-4513-bc90-5626ae7de879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
            "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
            "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
            "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
            "--------------------\n",
            "\n",
            "\n",
            "[Apr 28, 14:49:23] #> Creating directory .ragatouille/colbert/indexes/orca_paper \n",
            "\n",
            "\n",
            "[Apr 28, 14:49:26] [0] \t\t #> Encoding 87 passages..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            " 33%|███▎      | 1/3 [01:00<02:01, 60.61s/it]/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|██████████| 3/3 [02:46<00:00, 55.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Apr 28, 14:52:12] [0] \t\t avg_doclen_est = 357.8735656738281 \t len(local_sample) = 87\n",
            "[Apr 28, 14:52:12] [0] \t\t Creating 2,048 partitions.\n",
            "[Apr 28, 14:52:12] [0] \t\t *Estimated* 31,135 embeddings.\n",
            "[Apr 28, 14:52:12] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/orca_paper/plan.json ..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "used 18 iterations (26.6772s) to cluster 29579 items into 2048 clusters\n",
            "[0.032, 0.035, 0.029, 0.029, 0.029, 0.032, 0.032, 0.029, 0.03, 0.032, 0.03, 0.031, 0.031, 0.032, 0.031, 0.032, 0.029, 0.032, 0.03, 0.032, 0.03, 0.032, 0.031, 0.031, 0.029, 0.03, 0.032, 0.033, 0.031, 0.034, 0.029, 0.033, 0.032, 0.03, 0.031, 0.029, 0.035, 0.032, 0.031, 0.036, 0.033, 0.032, 0.03, 0.031, 0.03, 0.029, 0.031, 0.035, 0.032, 0.032, 0.03, 0.031, 0.032, 0.03, 0.031, 0.032, 0.033, 0.031, 0.035, 0.031, 0.032, 0.033, 0.032, 0.032, 0.033, 0.032, 0.029, 0.031, 0.028, 0.03, 0.033, 0.03, 0.031, 0.032, 0.032, 0.032, 0.033, 0.034, 0.032, 0.035, 0.034, 0.033, 0.03, 0.034, 0.029, 0.03, 0.032, 0.033, 0.029, 0.036, 0.03, 0.033, 0.031, 0.03, 0.031, 0.031, 0.032, 0.03, 0.03, 0.03, 0.031, 0.034, 0.03, 0.031, 0.031, 0.027, 0.031, 0.028, 0.03, 0.029, 0.032, 0.033, 0.033, 0.029, 0.032, 0.031, 0.032, 0.031, 0.03, 0.032, 0.03, 0.03, 0.032, 0.033, 0.031, 0.033, 0.03, 0.03]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Apr 28, 14:52:39] [0] \t\t #> Encoding 87 passages..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|███▎      | 1/3 [00:57<01:54, 57.10s/it]\u001b[A\n",
            " 67%|██████▋   | 2/3 [01:52<00:56, 56.10s/it]\u001b[A\n",
            "100%|██████████| 3/3 [02:33<00:00, 51.11s/it]\n",
            "1it [02:34, 154.76s/it]\n",
            "100%|██████████| 1/1 [00:00<00:00, 752.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Apr 28, 14:55:14] #> Optimizing IVF to store map from centroids to list of pids..\n",
            "[Apr 28, 14:55:14] #> Building the emb2pid mapping..\n",
            "[Apr 28, 14:55:14] len(emb2pid) = 31135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 2048/2048 [00:00<00:00, 60647.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Apr 28, 14:55:14] #> Saved optimized IVF to .ragatouille/colbert/indexes/orca_paper/ivf.pid.pt\n",
            "Done indexing!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'.ragatouille/colbert/indexes/orca_paper'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ask Query"
      ],
      "metadata": {
        "id": "7bCdgZWALqJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = RAG.search(query=\"What is instruction fine tuning?\")\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkHZDu3SLnl2",
        "outputId": "aeb59259-8743-4ad0-ce83-2bafe3e415f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading searcher for index orca_paper for the first time... This may take a few seconds\n",
            "[Apr 28, 14:56:05] #> Loading codec...\n",
            "[Apr 28, 14:56:05] #> Loading IVF...\n",
            "[Apr 28, 14:56:05] Loading segmented_lookup_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Apr 28, 14:56:32] #> Loading doclens...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 2671.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Apr 28, 14:56:32] #> Loading codes and residuals...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 125.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Apr 28, 14:56:32] Loading filter_pids_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Apr 28, 14:56:57] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
            "Searcher loaded!\n",
            "\n",
            "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
            "#> Input: . What is instruction fine tuning?, \t\t True, \t\t None\n",
            "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  7899,  2986, 17372,  1029,   102,   103,\n",
            "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
            "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
            "          103,   103])\n",
            "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'content': 'And you should choose a most \\nsuitable option out of \"A\", \"B\", \"C\", \"D\", and \"E\" based on your commonsense \\nknowledge. \\nInput:Solve this question: Dove non riusciresti a vedere la luce? \\nOptions: A scrivaniaB frigoriferoC sole D universoE atticoOutput: First, we need to arrange the data in ascending order: [2, 3, 7, 8, 10]. \\nSince there are 5 numbers, the median is the middle number, which is 7.\\nOutput: B frigorifero\\nOutput: Rydal Water lies between Windermere and Grasmere.\\nFigure 4: Instruction-tuning with GPT-49. Given user instructions for a task and an input,\\nthe system generates a response. Existing works like Alpaca [ 7], Vicuna [ 9] and variants\\nfollow a similar template to train small models with ⟨{user instruction, input}, output ⟩.\\n2 Preliminaries\\n2.1 Instruction Tuning\\nInstruction tuning [ 22] is a technique that allows pre-trained language models to learn\\nfrom input (natural language descriptions of the task) and response pairs, for example,\\n{\"instruction\": \"Arrange the words in the given sentence to form a grammatically\\ncorrect sentence.\", \"input\": \"the quickly brown fox jumped\", \"output\": \"the brown\\nfox jumped quickly\"} . Instruction tuning has been applied to both language-only and\\nmultimodal tasks. For language-only tasks, instruction tuning has been shown to improve\\nthe zero-shot and few-shot performance of models such as FLAN [ 22] and InstructGPT [ 5]\\non various benchmarks. For multimodal tasks, instruction tuning has been used to generate\\nsynthetic instruction-following data for language-image tasks, such as image captioning [ 23]\\nand visual question answering [24].\\nA wide range of works in recent times, including Alpaca [ 7], Vicuna [ 9], WizardLM [ 8] and\\nKoala [14], have adopted instruction-tuning to train smaller language models with outputs\\ngenerated from large foundation models from the GPT family.',\n",
              "  'score': 21.259580612182617,\n",
              "  'rank': 1,\n",
              "  'document_id': 'd6c007be-a8dc-4c41-a038-3fd333ca334c',\n",
              "  'passage_id': 12},\n",
              " {'content': '[21]Thomas Hartvigsen, Saadia Gabriel, Hamid Palangi, Maarten Sap, Dipankar Ray, and Ece\\nKamar. ToxiGen: A large-scale machine-generated dataset for adversarial and implicit hate\\nspeech detection. In Proceedings of the 60th Annual Meeting of the Association for Computa-\\ntional Linguistics (Volume 1: Long Papers) , pages 3309–3326. Association for Computational\\nLinguistics, 2022.\\n[22]Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan\\nDu, Andrew M. Dai, and Quoc V. Le. Finetuned language models are zero-shot learners, 2022.\\n[23]DeyaoZhu, JunChen, XiaoqianShen, XiangLi, andMohamedElhoseiny. Minigpt-4: Enhancing\\nvision-language understanding with advanced large language models, 2023.\\n[24]Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning, 2023.\\n[25] Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei,\\nAtharva Naik, Arjun Ashok, Arut Selvan Dhanasekaran, Anjana Arunkumar, David Stap, et al.\\nSuper-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks. In\\nProceedings of the 2022 Conference on Empirical Methods in Natural Language Processing ,\\npages 5085–5109, 2022.\\n[26]Mario Michael Krell, Matej Kosec, Sergio P. Perez, and Andrew Fitzgibbon. Efficient sequence\\npacking without cross-contamination: Accelerating large language models without impacting\\nperformance, 2022.\\n[27] Awesome chatgpt prompts, 2023. URL https://github.com/f/awesome-chatgpt-prompts .\\n[28]Weijia Xu, Andrzej Banburski-Fahey, and Nebojsa Jojic. Reprompting: Automated chain-of-\\nthought prompt inference through gibbs sampling, 2023.',\n",
              "  'score': 18.882606506347656,\n",
              "  'rank': 2,\n",
              "  'document_id': 'd6c007be-a8dc-4c41-a038-3fd333ca334c',\n",
              "  'passage_id': 84},\n",
              " {'content': 'This alignment is accomplished by fine-tuning the models via supervised learning on\\ndemonstrations of prompts and desired model behavior, and through reinforcement learning\\nfrom human preferences [5].\\nAs these models continue to evolve and become more powerful, an intriguing question arises:\\nCan we use the model itself to supervise its own behavior or that of other AI models? Bai\\net al.[6]have shown that by sampling output from an initial model, generating revisions,\\nand then fine-tuning the original model based on these revised responses, model behavior\\ncan be controlled more effectively and can be made more harmless, with significantly fewer\\nhuman labels.\\nRecently, there has been an influx of studies using LFMs like ChatGPT and GPT-4 as\\nteachers to generate large datasets, for instruction tuning , and to train smaller models,\\nsuch as Alpaca [ 7], WizardLM [ 8] and Vicuna [ 9]. While these models can produce content\\nthat matches the style of their teachers, they often fall short in terms of the reasoning and\\ncomprehension skills displayed by the larger foundation models.\\n423.348.9 49.7\\n0102030405060\\nVicuna-13B ChatGPT Orca-13BAggregate Accuracy (%)BigBench -Hard (Zero -shot, MCQ)Figure 3: For complex zero-shot reasoning tasks in BigBench-Hard, Orca achieves parity\\nwith ChatGPT (without any exemplar or CoT) with task performances shown in Figure 12.\\nTake, for example, the 13-billion parameter instruction-tuned model, Vicuna [ 9] (with\\nLLAMA-13B [ 10] as the base), which is widely regarded as one of the best models in its\\nfamily, as evidenced by its performance on leaderboards like OpenLLM3and ChatArena4.\\nAs illustrated in Figure 1, the widely-used evaluation method of using GPT-4 as the judge\\nsuggests that Vicuna retains 92%of ChatGPT’s quality. However, a more meticulous\\nevaluation on reasoning benchmarks against human labels finds Vicuna to retain only 64%\\nof ChatGPT’s quality on professional and academic exams (see Figure 2), and only 48%of\\nChatGPT’s quality on complex benchmarks like BigBench-hard [ 11] (see Figure 3)5.',\n",
              "  'score': 18.104232788085938,\n",
              "  'rank': 3,\n",
              "  'document_id': 'd6c007be-a8dc-4c41-a038-3fd333ca334c',\n",
              "  'passage_id': 7},\n",
              " {'content': 'For example, we notice\\nthat models that are instruction-tuned with GPT-4 responses tend to generate longer texts\\nthat GPT-4 prefers over shorter ones; as well as GPT-4 has a bias in the order of the candidate\\nresponses. We will show that such auto-evaluation measures overestimate the abilities of\\nsmaller models compared to LFMs, as the former are much weaker in comprehension and\\nreasoning skills.\\n1.2 Key Contributions\\nIn this research, our focus is on addressing the challenges mentioned above, specifically with:\\nExplanation tuning: We augment⟨query, response⟩pairs with detailed responses from\\nGPT-4 that explain the reasoning process of the teacher as it generates the response. These\\nprovide the student with additional signals for learning. We leverage system instructions (e.g..,\\nexplain like I’m five, think step-by-step and justify your response , etc.) to\\nelicit such explanations. This is in contrast to vanilla instruction tuning, which only uses the\\nprompt and the LFM response for learning, providing little opportunity for mimicking the\\nLFM’s “thought” process.\\nScaling tasks and instructions: We utilize the Flan 2022 Collection [ 19] as it provides\\nan extensive public assortment of tasks and instructions. Particularly, we use FLAN-\\nv2, supplemented with high-quality templates, advanced formatting patterns, and data\\naugmentations. Even though FLAN holds tens of millions of instructions, we selectively\\nsample from the task collection to form a diverse mixture of tasks, which we then further\\nsub-sample to generate complex prompts. These prompts are used to query LFMs like\\nChatGPT and GPT-4, thus creating a rich and diverse training set. We collect 5million\\nChatGPT responses, from which 1million is further sampled to acquire GPT-4 responses.\\nWe demonstrate how ChatGPT as a teacher assistant helps in progressive learning.',\n",
              "  'score': 16.73236656188965,\n",
              "  'rank': 4,\n",
              "  'document_id': 'd6c007be-a8dc-4c41-a038-3fd333ca334c',\n",
              "  'passage_id': 10},\n",
              " {'content': 'A wide range of works in recent times, including Alpaca [ 7], Vicuna [ 9], WizardLM [ 8] and\\nKoala [14], have adopted instruction-tuning to train smaller language models with outputs\\ngenerated from large foundation models from the GPT family. As outlined in Section 1.1,\\na significant drawback with all these works has been both limited task diversity, query\\ncomplexity and small-scale training data in addition to limited evaluation overstating the\\nbenefits of such approach.\\n2.2 Role of System Instructions\\nVanilla instruction-tuning (refer to Figure 4 for examples) often uses input, response pairs\\nwith short and terse responses. Such responses when used to train smaller models, as in\\nexisting works, give them limited ability to trace the reasoning process of the LFM. In\\nconstrast, system instructions10in recent LFMs like GPT-4 can be used to provide guidance\\n9GPT-4 inference hyper-parameters in Azure OpenAI interface set as: temperature=0.7,\\ntop_p=0.95, frequency_penalty=0, presence_penalty=0, stop=None.\\n10System instructions are part of the Chat Completion API, which is a new dedicated API for\\ninteracting with the ChatGPT and GPT-4 models.\\n7System Instruction: You are an AI assistant. User will you give you a task. Your \\ngoal is to complete the task as faithfully as you can. While performing the task \\nthink step-by-step and justify your steps.\\nUser Instruction: Use the given data to calculate the median.\\nInput:[7, 3, 8, 2, 10]\\nSystem Instruction: You are an AI assistant. User will you give you a task. Your \\ngoal is to complete the task as faithfully as you can. While performing the task \\nthink step-by-step and justify your steps.\\nUser Instruction: Answer this question.\\nInput:Which small lake lies between Windermere and Grasmere?System Instruction: You are an AI assistant. Provide a detailed answer so user \\ndon\\'t need to search outside to understand the answer.\\nUser Instruction: In this task, you will be presented with a question having \\nmultiple possible answers in Italian language. And you should choose a most \\nsuitable option out of \"A\", \"B\", \"C\", \"D\", and \"E\" based on your commonsense \\nknowledge.',\n",
              "  'score': 16.5113525390625,\n",
              "  'rank': 5,\n",
              "  'document_id': 'd6c007be-a8dc-4c41-a038-3fd333ca334c',\n",
              "  'passage_id': 13},\n",
              " {'content': 'Task diversity and data scaling. Human-contributed conversations in ShareGPT are a\\nvaluable source of data, but they also have some limitations. They tend to favor creative\\n3https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard\\n4https://chat.lmsys.org/?arena\\n5ChatGPT may have data contamination issues with respect to BigBench\\n6https://sharegpt.com/\\n5content generation and information-seeking queries over other types of tasks. Therefore,\\nmodels trained on such natural conversations may capture the style but not the reasoning\\nprocess of the LFMs – demonstrated in the performance of Vicuna in Figures 2 and 3.\\nAdditionally, such mode of data collection is also limited in scale. Table 1 shows an overview\\nof the size of data and tuning methods employed in recent popular instruction tuning works.\\nLimited imitation signals. Existing methods rely on immitation learning from\\n⟨query, response⟩pairs generated by the teacher model. However, this provides limited\\nsignals to trace the reasoning process of the teacher. Prior works [ 15,16] on open-box model\\nshow that richer signals such as logits, intermediate representations and attention states can\\nsignificantly improve distillation performance. While they are not accessible for closed-box\\nLFM’s7, recent work [ 17] demonstrates that richer signals like LFM rationales can help close\\nthe gap for task-specific distillation.\\nEvaluation: Previous studies on instruction tuning of small models with LFMs are severely\\nlimited in their evaluation protocol. They often rely on GPT-4 for auto-evaluation by asking\\nit to compare the outputs of two systems with a prompt like “given responses from system\\n1 (reference) and system 2 (target), which one is better?”. However, this approach has\\nseveral drawbacks, such as the small size of test sets (e.g., 80instructions in Vicuna and 218\\ninstructions in WizardLM) and the biases of GPT-4 as the judge [ 18]. For example, we notice\\nthat models that are instruction-tuned with GPT-4 responses tend to generate longer texts\\nthat GPT-4 prefers over shorter ones; as well as GPT-4 has a bias in the order of the candidate\\nresponses.',\n",
              "  'score': 15.737509727478027,\n",
              "  'rank': 6,\n",
              "  'document_id': 'd6c007be-a8dc-4c41-a038-3fd333ca334c',\n",
              "  'passage_id': 9},\n",
              " {'content': 'Step 1: Identify the location of Windermere and Grasmere. They are both \\nlocated in the Lake District National Park, in the county of Cumbria, England.\\nStep 2: Research the lakes in the Lake District. The Lake District is known for \\nits many lakes, so I will look for a list of lakes in the area and their locations in \\nrelation to Windermere and Grasmere.\\nStep 3: Find the small lake between Windermere and Grasmere. \\nAfter researching the lakes in the Lake District, I found that Rydal Water is a \\nsmall lake situated between Windermere and Grasmere.Figure 5: Explanation-tuning with GPT-4. In addition to user instructions and input, system\\ninstructions are provided to guide the system to form a well-reasoned and cogent response.\\nSystem instructions are sampled from a diverse instruction set including chain-of-thought\\nreasoning steps, explain like I’m five, being helpful and informative, etc. Such rich and\\nwell-structured response allows tuning small models to mimic the thinking process of GPT-4\\non⟨{system instruction, user instruction, input}, output ⟩pairs.\\nto the model on how to behave and respond. They are written in natural language and\\nseparated from the user messages by using the role of “system” in the JSON request. System\\ninstructions can specify the tone, task, format, and limitations of the model’s responses.\\nSystem instructions are also a way of improving the safety of model responses. For example,\\na set of system instructions designed for safety harness could be:\\n•The assistant must not generate harmful or offensive content.\\n•The assistant must respect the privacy and consent of the user.\\n•The assistant must acknowledge its limitations and uncertainties.\\n3 Explanation Tuning\\nTo address the shortcomings of existing works, we tap into large-scale training data with\\ndiverse tasks augmented with complex instructions and rich signals. Specifically, our data\\ncontains human and augmented system instructions for a large collection of tasks sampled\\nfrom FLAN-v2 (aka Flan 2022) [ 19]. Given the large size of the FLAN-v2 collection and\\nvarying number of examples for constituent datasets and tasks, we sample from a mixture of\\ntasks from different categories (described in the next section) to create our training data.',\n",
              "  'score': 15.224943161010742,\n",
              "  'rank': 7,\n",
              "  'document_id': 'd6c007be-a8dc-4c41-a038-3fd333ca334c',\n",
              "  'passage_id': 15},\n",
              " {'content': 'URL https://github.com/f/awesome-chatgpt-prompts .\\n[28]Weijia Xu, Andrzej Banburski-Fahey, and Nebojsa Jojic. Reprompting: Automated chain-of-\\nthought prompt inference through gibbs sampling, 2023.\\n[29]Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan\\nLi, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu,\\nZhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Alex Castro-Ros, Marie\\nPellat, Kevin Robinson, Dasha Valter, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent\\nZhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob\\nDevlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei. Scaling instruction-finetuned\\nlanguage models, 2022.\\n[30]Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy\\nJones, Nicholas Joseph, Ben Mann, Nova DasSarma, Nelson Elhage, Zac Hatfield-Dodds, Danny\\nHernandez, Jackson Kernion, Kamal Ndousse, Catherine Olsson, Dario Amodei, Tom Brown,\\nJack Clark, Sam McCandlish, Chris Olah, and Jared Kaplan. A general language assistant as a\\nlaboratory for alignment, 2021.\\n50[31]Stephanie Lin, Jacob Hilton, and Owain Evans. TruthfulQA: Measuring how models mimic\\nhuman falsehoods. In Proceedings of the 60th Annual Meeting of the Association for Computa-\\ntional Linguistics (Volume 1: Long Papers) , pages 3214–3252. Association for Computational\\nLinguistics, 2022.\\n[32] OpenAI. Gpt-4 technical report, 2023.\\n[33]Tommaso Caselli, Valerio Basile, Jelena Mitrovic, and M. Granitzer. Hatebert: Retraining bert\\nfor abusive language detection in english.',\n",
              "  'score': 14.724531173706055,\n",
              "  'rank': 8,\n",
              "  'document_id': 'd6c007be-a8dc-4c41-a038-3fd333ca334c',\n",
              "  'passage_id': 85},\n",
              " {'content': '†Correspondence to subhabrata.mukherjee@microsoft.com\\nWe are working with our legal team to publicly release a diff of the model weights in accordance\\nwith LLaMA’s release policy to be published at https://aka.ms/orca-lm .\\nWork in progress.arXiv:2306.02707v1  [cs.CL]  5 Jun 2023Contents\\n1 Introduction 4\\n1.1 Challenges with Existing Methods . . . . . . . . . . . . . . . . . . . . . . . . 5\\n1.2 Key Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n2 Preliminaries 7\\n2.1 Instruction Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n2.2 Role of System Instructions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3 Explanation Tuning 8\\n3.1 Dataset Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\\n3.1.1 System Messages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .',\n",
              "  'score': 14.537232398986816,\n",
              "  'rank': 9,\n",
              "  'document_id': 'd6c007be-a8dc-4c41-a038-3fd333ca334c',\n",
              "  'passage_id': 1},\n",
              " {'content': 'We collect 5million\\nChatGPT responses, from which 1million is further sampled to acquire GPT-4 responses.\\nWe demonstrate how ChatGPT as a teacher assistant helps in progressive learning.\\nEvaluation: We assess the generative, reasoning, and comprehension abilities of Orca, under\\na range of settings: (i) AutoEvaluation with GPT-4 on existing evaluation sets from Vicuna,\\nWizardLM and the awesome prompts collection8; (ii) Academic benchmarks like Big-Bench\\nHard [4] and TruthfulQA [ 20]; (iii) Professional and Academic exams like SAT, LSAT, GRE,\\nGMAT from AGIEval [ 1]; (iv) Safety evaluation with ToxiGen [ 21] to test toxic language\\ngeneration and hate speech detection across different minority groups. Finally, we provide\\ncase-studies to compare the generation and reasoning abilities of Orca against OpenAI LFMs\\nlike ChatGPT and GPT-4, and instruction-tuned smaller model like Vicuna.\\n7Note that OpenAI API’s do give access to the top-5logits for each token.\\n8https://prompts.chat/\\n6Model Tuning Method Data Size Teacher\\nAlpaca Simple Instructions / Self-instruct 52K text-da-vinci-003\\nVicuna User Instructions / Natural 70K ChatGPT\\nDolly User Instructions / Natural 15K Human\\nWizardLM Complex Instructions / Evol-instruct 250K ChatGPT\\nOrca Complex Instructions / Explanations 5M ChatGPT (5M)\\n∩GPT-4 (1M)\\nTable 1: Overview of popular models instruction tuned with OpenAI large foundation models\\n(LFMs). Orca leverages complex instructions and explanations for progressive learning.\\nUser Instruction: Use the given data to calculate the median. \\nInput:[7, 3, 8, 2, 10]\\nUser Instruction: Answer this question.\\nInput:Which small lake lies between Windermere and Grasmere?User Instruction: In this task, you will be presented with a question having \\nmultiple possible answers in Italian language. And you should choose a most \\nsuitable option out of \"A\", \"B\", \"C\", \"D\", and \"E\" based on your commonsense \\nknowledge. \\nInput:Solve this question: Dove non riusciresti a vedere la luce?',\n",
              "  'score': 14.432781219482422,\n",
              "  'rank': 10,\n",
              "  'document_id': 'd6c007be-a8dc-4c41-a038-3fd333ca334c',\n",
              "  'passage_id': 11}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = RAG.search(query=\"What is instruction SQUAD V2.0?\",k=2)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOjdDU_2OSB8",
        "outputId": "259bfb88-a855-4845-afbf-2f5b1f986383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'content': '. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n3.1.2 Dataset Description and Sampling from the FLAN-v2 Collection . . . 9\\n3.1.3 ChatGPT as Teaching Assistant . . . . . . . . . . . . . . . . . . . . . 12\\n3.2 Training . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\n4 Experiment Setup 14\\n4.1 Baselines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\n4.2 Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\n4.2.1 Open-ended Generation Capabilities . . . . . . . . . . . . . . . . . . . 15\\n4.2.2 Reasoning Capabilities . . . . . . . . . . . . . . . . . . . . . . . . . .',\n",
              "  'score': 14.657217979431152,\n",
              "  'rank': 1,\n",
              "  'document_id': 'd6c007be-a8dc-4c41-a038-3fd333ca334c',\n",
              "  'passage_id': 2},\n",
              " {'content': 'A wide range of works in recent times, including Alpaca [ 7], Vicuna [ 9], WizardLM [ 8] and\\nKoala [14], have adopted instruction-tuning to train smaller language models with outputs\\ngenerated from large foundation models from the GPT family. As outlined in Section 1.1,\\na significant drawback with all these works has been both limited task diversity, query\\ncomplexity and small-scale training data in addition to limited evaluation overstating the\\nbenefits of such approach.\\n2.2 Role of System Instructions\\nVanilla instruction-tuning (refer to Figure 4 for examples) often uses input, response pairs\\nwith short and terse responses. Such responses when used to train smaller models, as in\\nexisting works, give them limited ability to trace the reasoning process of the LFM. In\\nconstrast, system instructions10in recent LFMs like GPT-4 can be used to provide guidance\\n9GPT-4 inference hyper-parameters in Azure OpenAI interface set as: temperature=0.7,\\ntop_p=0.95, frequency_penalty=0, presence_penalty=0, stop=None.\\n10System instructions are part of the Chat Completion API, which is a new dedicated API for\\ninteracting with the ChatGPT and GPT-4 models.\\n7System Instruction: You are an AI assistant. User will you give you a task. Your \\ngoal is to complete the task as faithfully as you can. While performing the task \\nthink step-by-step and justify your steps.\\nUser Instruction: Use the given data to calculate the median.\\nInput:[7, 3, 8, 2, 10]\\nSystem Instruction: You are an AI assistant. User will you give you a task. Your \\ngoal is to complete the task as faithfully as you can. While performing the task \\nthink step-by-step and justify your steps.\\nUser Instruction: Answer this question.\\nInput:Which small lake lies between Windermere and Grasmere?System Instruction: You are an AI assistant. Provide a detailed answer so user \\ndon\\'t need to search outside to understand the answer.\\nUser Instruction: In this task, you will be presented with a question having \\nmultiple possible answers in Italian language. And you should choose a most \\nsuitable option out of \"A\", \"B\", \"C\", \"D\", and \"E\" based on your commonsense \\nknowledge.',\n",
              "  'score': 13.014354705810547,\n",
              "  'rank': 2,\n",
              "  'document_id': 'd6c007be-a8dc-4c41-a038-3fd333ca334c',\n",
              "  'passage_id': 13}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use as a langchai Retriever to retrieve context"
      ],
      "metadata": {
        "id": "bHwjKLFxOl-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriver = RAG.as_langchain_retriever(k=3)\n",
        "retriver.invoke(\"What is instruction fine tuning?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSUTflLhOYSc",
        "outputId": "0c60e924-0d92-4c11-a797-352f2da02af6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='And you should choose a most \\nsuitable option out of \"A\", \"B\", \"C\", \"D\", and \"E\" based on your commonsense \\nknowledge. \\nInput:Solve this question: Dove non riusciresti a vedere la luce? \\nOptions: A scrivaniaB frigoriferoC sole D universoE atticoOutput: First, we need to arrange the data in ascending order: [2, 3, 7, 8, 10]. \\nSince there are 5 numbers, the median is the middle number, which is 7.\\nOutput: B frigorifero\\nOutput: Rydal Water lies between Windermere and Grasmere.\\nFigure 4: Instruction-tuning with GPT-49. Given user instructions for a task and an input,\\nthe system generates a response. Existing works like Alpaca [ 7], Vicuna [ 9] and variants\\nfollow a similar template to train small models with ⟨{user instruction, input}, output ⟩.\\n2 Preliminaries\\n2.1 Instruction Tuning\\nInstruction tuning [ 22] is a technique that allows pre-trained language models to learn\\nfrom input (natural language descriptions of the task) and response pairs, for example,\\n{\"instruction\": \"Arrange the words in the given sentence to form a grammatically\\ncorrect sentence.\", \"input\": \"the quickly brown fox jumped\", \"output\": \"the brown\\nfox jumped quickly\"} . Instruction tuning has been applied to both language-only and\\nmultimodal tasks. For language-only tasks, instruction tuning has been shown to improve\\nthe zero-shot and few-shot performance of models such as FLAN [ 22] and InstructGPT [ 5]\\non various benchmarks. For multimodal tasks, instruction tuning has been used to generate\\nsynthetic instruction-following data for language-image tasks, such as image captioning [ 23]\\nand visual question answering [24].\\nA wide range of works in recent times, including Alpaca [ 7], Vicuna [ 9], WizardLM [ 8] and\\nKoala [14], have adopted instruction-tuning to train smaller language models with outputs\\ngenerated from large foundation models from the GPT family.'),\n",
              " Document(page_content='[21]Thomas Hartvigsen, Saadia Gabriel, Hamid Palangi, Maarten Sap, Dipankar Ray, and Ece\\nKamar. ToxiGen: A large-scale machine-generated dataset for adversarial and implicit hate\\nspeech detection. In Proceedings of the 60th Annual Meeting of the Association for Computa-\\ntional Linguistics (Volume 1: Long Papers) , pages 3309–3326. Association for Computational\\nLinguistics, 2022.\\n[22]Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan\\nDu, Andrew M. Dai, and Quoc V. Le. Finetuned language models are zero-shot learners, 2022.\\n[23]DeyaoZhu, JunChen, XiaoqianShen, XiangLi, andMohamedElhoseiny. Minigpt-4: Enhancing\\nvision-language understanding with advanced large language models, 2023.\\n[24]Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning, 2023.\\n[25] Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei,\\nAtharva Naik, Arjun Ashok, Arut Selvan Dhanasekaran, Anjana Arunkumar, David Stap, et al.\\nSuper-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks. In\\nProceedings of the 2022 Conference on Empirical Methods in Natural Language Processing ,\\npages 5085–5109, 2022.\\n[26]Mario Michael Krell, Matej Kosec, Sergio P. Perez, and Andrew Fitzgibbon. Efficient sequence\\npacking without cross-contamination: Accelerating large language models without impacting\\nperformance, 2022.\\n[27] Awesome chatgpt prompts, 2023. URL https://github.com/f/awesome-chatgpt-prompts .\\n[28]Weijia Xu, Andrzej Banburski-Fahey, and Nebojsa Jojic. Reprompting: Automated chain-of-\\nthought prompt inference through gibbs sampling, 2023.'),\n",
              " Document(page_content='This alignment is accomplished by fine-tuning the models via supervised learning on\\ndemonstrations of prompts and desired model behavior, and through reinforcement learning\\nfrom human preferences [5].\\nAs these models continue to evolve and become more powerful, an intriguing question arises:\\nCan we use the model itself to supervise its own behavior or that of other AI models? Bai\\net al.[6]have shown that by sampling output from an initial model, generating revisions,\\nand then fine-tuning the original model based on these revised responses, model behavior\\ncan be controlled more effectively and can be made more harmless, with significantly fewer\\nhuman labels.\\nRecently, there has been an influx of studies using LFMs like ChatGPT and GPT-4 as\\nteachers to generate large datasets, for instruction tuning , and to train smaller models,\\nsuch as Alpaca [ 7], WizardLM [ 8] and Vicuna [ 9]. While these models can produce content\\nthat matches the style of their teachers, they often fall short in terms of the reasoning and\\ncomprehension skills displayed by the larger foundation models.\\n423.348.9 49.7\\n0102030405060\\nVicuna-13B ChatGPT Orca-13BAggregate Accuracy (%)BigBench -Hard (Zero -shot, MCQ)Figure 3: For complex zero-shot reasoning tasks in BigBench-Hard, Orca achieves parity\\nwith ChatGPT (without any exemplar or CoT) with task performances shown in Figure 12.\\nTake, for example, the 13-billion parameter instruction-tuned model, Vicuna [ 9] (with\\nLLAMA-13B [ 10] as the base), which is widely regarded as one of the best models in its\\nfamily, as evidenced by its performance on leaderboards like OpenLLM3and ChatArena4.\\nAs illustrated in Figure 1, the widely-used evaluation method of using GPT-4 as the judge\\nsuggests that Vicuna retains 92%of ChatGPT’s quality. However, a more meticulous\\nevaluation on reasoning benchmarks against human labels finds Vicuna to retain only 64%\\nof ChatGPT’s quality on professional and academic exams (see Figure 2), and only 48%of\\nChatGPT’s quality on complex benchmarks like BigBench-hard [ 11] (see Figure 3)5.')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}