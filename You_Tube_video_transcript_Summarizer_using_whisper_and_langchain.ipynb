{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMgVEp72DqsUhxUTjf7S7ot",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plaban1981/Langchain_usecases/blob/main/You_Tube_video_transcript_Summarizer_using_whisper_and_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NGuc6aIiEXM",
        "outputId": "55a05a5c-933e-4c1b-990c-11fcd70a8f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU openai langchain tiktoken pytube"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install git+https://github.com/openai/whisper.git -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTXr75N9q8B4",
        "outputId": "0853753b-42d0-4370-999e-a5ee5e299665"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from getpass import getpass\n",
        "#\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "#\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.text_splitter import CharacterTextSplitter,RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "import textwrap\n",
        "#\n",
        "from pytube import YouTube\n",
        "import whisper"
      ],
      "metadata": {
        "id": "qt8VJuQeichg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up Openai Key"
      ],
      "metadata": {
        "id": "565D5ryhjBCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrYGWmVrql6r",
        "outputId": "483f6496-d015-4627-ea35-7af9c1194f24"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instantiate models"
      ],
      "metadata": {
        "id": "NPErDOMBrFCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_models():\n",
        "  model = whisper.load_model(\"large\")\n",
        "  return model"
      ],
      "metadata": {
        "id": "z4aMPRlbqqzs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4Ca0GJxrdNS",
        "outputId": "ede0f404-7027-443c-f1e6-60e83e64b3f5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 2.87G/2.87G [00:21<00:00, 141MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding('cl100k_base')\n",
        "#\n",
        "def tiktoken_len(text):\n",
        "  tokens = tokenizer.encode(text,disallowed_special=())\n",
        "  return len(tokens)"
      ],
      "metadata": {
        "id": "AYsMZ01wtAKD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_yt(url,model):\n",
        "  yt = YouTube(url)\n",
        "  audio = yt.streams.filter(only_audio=True).first().download()\n",
        "  print(\"Audio downloaded\")\n",
        "\n",
        "  transcript = model.transcribe(audio,fp16=False)['text']\n",
        "  print(transcript)\n",
        "\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size =1000,\n",
        "                                                 chunk_overlap=20,\n",
        "                                                 length_function = tiktoken_len,\n",
        "                                                 separators = ['\\n\\n','\\n','  ',' '])\n",
        "  texts = text_splitter.split_text(transcript)\n",
        "  docs = [Document(page_content=t) for t in texts]\n",
        "  print(\"Text split\")\n",
        "  return docs"
      ],
      "metadata": {
        "id": "IB9pj9N_rflV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(docs):\n",
        "  #\n",
        "  prompt_template = \"\"\"You are an expert at making strong factual summarizations.\n",
        "  Extract the key facts out of the text provided enclosed within 3 bacticks. Don't include opinions.\n",
        "  Give each fact a number and keep them short sentences. :\\n\\n\"\n",
        "  ```{text}```\"\"\"\n",
        "  PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
        "  #\n",
        "  llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
        "  #\n",
        "  chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=PROMPT)\n",
        "  #\n",
        "  response = chain.run(docs)\n",
        "  return response\n",
        "\n"
      ],
      "metadata": {
        "id": "uWt61h2NtWLq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transcribe the Youtube link provided"
      ],
      "metadata": {
        "id": "OZi58CfYvEGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "url = \"https://youtu.be/I2ZK3ngNvvI\"\n",
        "docs = summarize_yt(url,model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUskvk8Juj3K",
        "outputId": "aaccff8a-50a0-4a7c-efc4-752d96dd8293"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio downloaded\n",
            " You're one of the greatest teachers of machine learning, AI ever, from CS231N to today. What advice would you give to beginners interested in getting into machine learning? Beginners are often focused on like what to do, and I think the focus should be more like how much you do. So I am kind of like believer on a high level in this 10,000 hours kind of concept where just kind of have to just pick the things where you can spend time and you care about and you're interested in. You literally have to put in 10,000 hours of work. It doesn't even matter as much like where you put it and you'll iterate and you'll improve and you'll waste some time. I don't know if there's a better way. You need to put in 10,000 hours, but I think it's actually really nice because I feel like there's some sense of determinism about being an expert at a thing. If you spend 10,000 hours, you can literally pick an arbitrary thing. And I think if you spend 10,000 hours of deliberate effort and work, you actually will become an expert at it. And so I think that's kind of like a nice thought. And so basically I would focus more on like are you spending 10,000 hours? That's what I would focus on. So and then thinking about what kind of mechanisms maximize your likelihood of getting to 10,000 hours, which for us silly humans means probably forming a daily habit of like every single day actually doing the thing. Whatever helps you. So I do think to a large extent it's a psychological problem for yourself. One other thing that I think is helpful for the psychology of it is many times people compare themselves to others in the area. I think this is very harmful. Only compare yourself to you from some time ago, like say a year ago. Are you better than you a year ago? This is the only way to think. And I think this, then you can see your progress and it's very motivating. That's so interesting that focus on the quantity of hours. Because I think a lot of people in the beginner stage, but actually throughout, get paralyzed by the choice. Like which one do I pick? This path or this path? Like they'll literally get paralyzed by like which IDE to use. Well they're worried, yeah. They're worried about all these things. But the thing is, you will waste time doing something wrong. You will eventually figure out it's not right. You will accumulate scar tissue. And next time you'll grow stronger. Because next time you'll have the scar tissue and next time you'll learn from it. And now next time you come to a similar situation, you'll be like, oh, I messed up. I've spent a lot of time working on things that never materialize into anything. And I have all that scar tissue and I have some intuitions about what was useful, what wasn't useful, how things turned out. So all those mistakes were not dead work. So I just think you should focus on working. What have you done? What have you done last week? That's a good question actually to ask for a lot of things, not just machine learning. It's a good way to cut the, I forgot what the term we use, but the fluff, the blubber, whatever, the inefficiencies in life. What do you love about teaching? You seem to find yourself often in the, like drawn to teaching. You're very good at it, but you're also drawn to it. I mean, I don't think I love teaching. I love happy humans. And happy humans like when I teach. I wouldn't say I hate teaching. I tolerate teaching. But it's not like the act of teaching that I like. It's that I have something, I'm actually okay at it. I'm okay at teaching and people appreciate it a lot. And so I'm just happy to try to be helpful. And teaching itself is not like the most, I mean, it can be really annoying, frustrating. I was working on a bunch of lectures just now. I was reminded back to my days of 231N just how much work it is to create some of these materials and make them good. The amount of iteration and thought and you go down blind alleys and just how much you change it. So creating something good in terms of educational value is really hard. And it's not fun. It's difficult. So people should definitely go watch your new stuff you put out. There are lectures where you're actually building the thing from, like you said, the code is truth. So discussing back propagation by building it, by looking through it, just the whole thing. So how difficult is that to prepare for? I think that's a really powerful way to teach. Did you have to prepare for that or are you just live thinking through it? I will typically do like, say, three takes and then I take like the better take. So I do multiple takes and I take some of the better takes and then I just build out a lecture that way. Sometimes I have to delete 30 minutes of content because it just went down an alley that I didn't like too much. So there's a bunch of iteration and it probably takes me, you know, somewhere around 10 hours to create one hour of content. To get one hour. It's interesting. I mean, is it difficult to go back to the basics? Do you draw a lot of like wisdom from going back to the basics? Yeah. I like the propagation loss functions, where they come from. And one thing I like about teaching a lot, honestly, is it definitely strengthens your understanding. So it's not a purely altruistic activity. It's a way to learn. If you have to explain something to someone, you realize you have gaps in knowledge. And so I even surprised myself in those lectures. Like, oh, so the result will obviously look at this and then the result doesn't look like it. And I'm like, okay, I thought I understood this. That's why it's really cool. Literally code, you run it in a notebook and it gives you a result and you're like, oh, wow. And like actual numbers, actual input, actual code. It's not mathematical symbols, etc. The source of truth is the code. It's not slides. It's just like, let's build it. It's beautiful. You're a rare human in that sense. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah.\n",
            "Text split\n",
            "CPU times: user 1min 13s, sys: 157 ms, total: 1min 13s\n",
            "Wall time: 1min 14s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Response generated by Davinci"
      ],
      "metadata": {
        "id": "CEZcJIrfz-c_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "response = summarize(docs)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXHxLfSQvVkR",
        "outputId": "c39915e4-1531-4e21-c5b2-9206585dfa2f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Tue, 01 Aug 2023 06:25:05 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7efbf8be8d661403-ORD', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. The advice given to beginners interested in machine learning is to focus on the quantity of hours spent on learning and practicing.\n",
            "2. Putting in 10,000 hours of deliberate effort and work is believed to make someone an expert in a particular field.\n",
            "3. It is recommended to compare one's progress to their past self rather than comparing oneself to others.\n",
            "4. Beginners often get paralyzed by the choices and worry about making mistakes, but mistakes and wasted time can lead to learning and growth.\n",
            "5. The speaker is not particularly fond of teaching, but enjoys being helpful and appreciated by others.\n",
            "6. Creating educational materials and lectures requires a lot of work, iteration, and thought.\n",
            "7. The speaker prepares for lectures by doing multiple takes and selecting the better ones, and it takes around 10 hours to create one hour of content.\n",
            "8. Teaching helps strengthen the speaker's understanding and reveals gaps in knowledge.\n",
            "9. The speaker finds it fascinating to see the actual results of code and considers it the source of truth in teaching.\n",
            "CPU times: user 1.41 s, sys: 236 ms, total: 1.65 s\n",
            "Wall time: 5min 28s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Response Generated by GPT3"
      ],
      "metadata": {
        "id": "9-ZaIey00kBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "response = summarize(docs)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4jxZfEm0mby",
        "outputId": "24ace6c3-2575-4c35-ae3d-a6b37173be5f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Beginners in machine learning should focus on the quantity of hours they spend practicing and learning.\n",
            "2. Putting in 10,000 hours of deliberate effort and work can make someone an expert in a particular field.\n",
            "3. It is important to compare one's progress to their past self rather than comparing themselves to others.\n",
            "4. Beginners should not get paralyzed by the choices and mistakes they make, as they can learn and grow from them.\n",
            "5. Teaching can be challenging and time-consuming, requiring a lot of iteration and thought to create good educational materials.\n",
            "6. Teaching helps strengthen one's understanding of the subject matter.\n",
            "7. Explaining concepts to others can reveal gaps in one's knowledge.\n",
            "8. Building and running code is a powerful way to learn and understand machine learning concepts.\n",
            "CPU times: user 110 ms, sys: 6.96 ms, total: 117 ms\n",
            "Wall time: 5.55 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Response generated by GP4"
      ],
      "metadata": {
        "id": "82KyzKgv0E6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "response = summarize(docs)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Rl-z5qdzxxK",
        "outputId": "f2457859-b658-4f69-a254-447f9670a8a9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. The speaker believes in the concept of spending 10,000 hours on a task to become an expert at it.\n",
            "2. The speaker advises beginners in machine learning to focus on the quantity of hours spent learning rather than what specifically to learn.\n",
            "3. The speaker suggests forming a daily habit to maximize the likelihood of reaching 10,000 hours of practice.\n",
            "4. The speaker discourages comparing oneself to others, instead suggesting to compare oneself to their past self to track progress.\n",
            "5. The speaker acknowledges that mistakes and wasted time are part of the learning process and contribute to growth.\n",
            "6. The speaker does not particularly love teaching, but does it because people appreciate it and it makes them happy.\n",
            "7. The speaker finds creating educational materials to be hard work and not always enjoyable.\n",
            "8. The speaker typically takes multiple takes when creating a lecture and it takes approximately 10 hours to create one hour of content.\n",
            "9. The speaker finds that teaching strengthens their own understanding and helps identify gaps in knowledge.\n",
            "10. The speaker believes that the source of truth in teaching machine learning is the code, not slides or mathematical symbols.\n",
            "CPU times: user 194 ms, sys: 16.4 ms, total: 210 ms\n",
            "Wall time: 26.5 s\n"
          ]
        }
      ]
    }
  ]
}